{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeCoY3TqrFPi",
        "outputId": "b8a1b44e-34d9-4c31-b048-fb21a78a4990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXu6D-nv_Z3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e7f544-13c1-4f4e-bc53-1aea2d0269b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-chess in /usr/local/lib/python3.10/dist-packages (1.999)\n",
            "Requirement already satisfied: chess<2,>=1 in /usr/local/lib/python3.10/dist-packages (from python-chess) (1.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-chess\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPvv15KtoS7k"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv('/content/drive/MyDrive/chessData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yQdZKrXsNU3"
      },
      "outputs": [],
      "source": [
        "dataframe.head()\n",
        "d=dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQdVPluX9Ngk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e6ec76-b39f-4173-dae9-54330dc7c56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-f5683cca8c9d>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  d1['Evaluation'] = d1['Evaluation'].astype(float)\n"
          ]
        }
      ],
      "source": [
        "d.shape\n",
        "d1=d.iloc[0:1000000 ,:]\n",
        "d1.shape\n",
        "d1 = d1[~d1['Evaluation'].str.contains('\\ufeff|#', na=False)]\n",
        "d1['Evaluation'] = d1['Evaluation'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import chess\n",
        "\n",
        "def generate_bitboard_with_moves(fen):\n",
        "  board = chess.Board(fen)\n",
        "\n",
        "\n",
        "  bitboards = np.zeros((14, 8, 8), dtype=np.int8)\n",
        "\n",
        "  for square in chess.SQUARES:\n",
        "         piece = board.piece_at(square)\n",
        "\n",
        "         if piece is not None:\n",
        "\n",
        "            piece_type = piece.piece_type - 1 if piece.color == chess.WHITE else piece.piece_type + 5\n",
        "\n",
        "\n",
        "            bitboards[piece_type, square // 8, square % 8] = (piece_type + 1)\n",
        "\n",
        "\n",
        "            # legal_moves = [move.to_square for move in board.legal_moves if move.from_square == square]\n",
        "\n",
        "\n",
        "            # for move_square in legal_moves:\n",
        "            #     bitboards[piece_type, move_square // 8, move_square % 8] = piece_type + 1\n",
        "                # Add information about en passant square\n",
        "  if board.has_legal_en_passant():\n",
        "        ep_square = board.ep_square\n",
        "        bitboards[12, ep_square // 8, ep_square % 8] = 1\n",
        "\n",
        "    # Add information about whose move it is\n",
        "  bitboards[13, :, :] = 1 if board.turn == chess.WHITE else 0\n",
        "  return bitboards\n",
        "bitboard_dataset = [generate_bitboard_with_moves(fen) for fen in d1['FEN']]"
      ],
      "metadata": {
        "id": "mBXGrD1GbmOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import chess\n",
        "\n",
        "# def generate_bitboard_with_moves(fen):\n",
        "#     board = chess.Board(fen)\n",
        "\n",
        "#     # Initialize empty 3D matrix of bitboards for each piece type\n",
        "#     bitboards = np.zeros((12, 8, 8), dtype=np.int8)\n",
        "\n",
        "#     # Iterate over all squares on the board\n",
        "#     for square in chess.SQUARES:\n",
        "#         piece = board.piece_at(square)\n",
        "\n",
        "#         if piece is not None:\n",
        "#             # Determine piece type\n",
        "#             piece_type = piece.piece_type - 1 if piece.color == chess.WHITE else piece.piece_type + 5\n",
        "\n",
        "#             # Mark the piece's position on the bitboard\n",
        "#             bitboards[piece_type, square // 8, square % 8] = (piece_type + 1)*11\n",
        "\n",
        "#             # Generate legal moves for the piece at the square\n",
        "#             legal_moves = [move.to_square for move in board.legal_moves if move.from_square == square]\n",
        "\n",
        "#             # Mark legal moves on the bitboard\n",
        "#             for move_square in legal_moves:\n",
        "#                 bitboards[piece_type, move_square // 8, move_square % 8] = piece_type + 1\n",
        "\n",
        "#     return bitboards\n",
        "# bitboard_dataset = [generate_bitboard_with_moves(fen) for fen in d1['FEN']]"
      ],
      "metadata": {
        "id": "trBRMhJG-GBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bitboard_dataset =np.load(\"/content/drive/MyDrive/my_array.npy\")"
      ],
      "metadata": {
        "id": "UY7OvXOQIYmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bitboard_dataset=np.array(bitboard_dataset)\n",
        "print(bitboard_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFSsXYpsWrou",
        "outputId": "81f67db6-8c32-4d0d-e00c-c51551f36b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0  0  0  0  0  0  0  0]\n",
            "  [ 1  1  1  1  0  1  1  1]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  2  0  0  0  0  2  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  3  0  0  3  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 4  0  0  0  0  0  0  4]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  5  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  6  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 7  7  7  7  7  7  7  7]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  8  0  0  0  0  8  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  9  0  0  9  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [10  0  0  0  0  0  0 10]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0 11  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0 12  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/my_array.npy', bitboard_dataset)"
      ],
      "metadata": {
        "id": "bnfn9WPEni1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L54mHai3qOOI"
      },
      "outputs": [],
      "source": [
        "labels=d1['Evaluation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9qEfiSErKrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0796edf8-f0dd-45d2-bf81-21132a7b3e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "635/635 [==============================] - 9s 7ms/step - loss: 422998.3125 - mean_absolute_error: 230.5954 - val_loss: 394697.6250 - val_mean_absolute_error: 226.6120\n",
            "Epoch 2/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 391844.4688 - mean_absolute_error: 229.7552 - val_loss: 370266.8750 - val_mean_absolute_error: 228.8647\n",
            "Epoch 3/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 376491.0625 - mean_absolute_error: 234.2701 - val_loss: 364454.5312 - val_mean_absolute_error: 231.3113\n",
            "Epoch 4/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 369589.7500 - mean_absolute_error: 235.4471 - val_loss: 360375.1875 - val_mean_absolute_error: 235.4063\n",
            "Epoch 5/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 365302.2500 - mean_absolute_error: 235.4461 - val_loss: 358746.8125 - val_mean_absolute_error: 245.5010\n",
            "Epoch 6/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 361300.5312 - mean_absolute_error: 235.3567 - val_loss: 352989.5938 - val_mean_absolute_error: 232.9120\n",
            "Epoch 7/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 357137.4688 - mean_absolute_error: 235.0309 - val_loss: 351064.9062 - val_mean_absolute_error: 235.2993\n",
            "Epoch 8/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 354392.6875 - mean_absolute_error: 234.8765 - val_loss: 352416.1875 - val_mean_absolute_error: 236.9696\n",
            "Epoch 9/1000\n",
            "635/635 [==============================] - 6s 9ms/step - loss: 351287.6875 - mean_absolute_error: 234.4024 - val_loss: 347250.1250 - val_mean_absolute_error: 231.4881\n",
            "Epoch 10/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 348464.1250 - mean_absolute_error: 234.3019 - val_loss: 347892.1562 - val_mean_absolute_error: 231.5289\n",
            "Epoch 11/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 345995.8438 - mean_absolute_error: 234.1474 - val_loss: 350026.2812 - val_mean_absolute_error: 234.4430\n",
            "Epoch 12/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 343867.3750 - mean_absolute_error: 233.5888 - val_loss: 345417.6875 - val_mean_absolute_error: 232.5513\n",
            "Epoch 13/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 341611.3750 - mean_absolute_error: 233.8340 - val_loss: 350243.3125 - val_mean_absolute_error: 244.6069\n",
            "Epoch 14/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 339465.0938 - mean_absolute_error: 233.3277 - val_loss: 346833.2500 - val_mean_absolute_error: 231.9846\n",
            "Epoch 15/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 337020.8438 - mean_absolute_error: 233.0335 - val_loss: 345347.2500 - val_mean_absolute_error: 234.9740\n",
            "Epoch 16/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 334757.7812 - mean_absolute_error: 232.5303 - val_loss: 348836.7500 - val_mean_absolute_error: 235.5522\n",
            "Epoch 17/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 332705.6562 - mean_absolute_error: 231.9297 - val_loss: 349120.1250 - val_mean_absolute_error: 243.9126\n",
            "Epoch 18/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 330509.8438 - mean_absolute_error: 231.6322 - val_loss: 352066.6562 - val_mean_absolute_error: 237.6368\n",
            "Epoch 19/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 328872.7188 - mean_absolute_error: 231.2456 - val_loss: 349823.5625 - val_mean_absolute_error: 232.3005\n",
            "Epoch 20/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 326237.2188 - mean_absolute_error: 230.4605 - val_loss: 345184.3750 - val_mean_absolute_error: 231.6555\n",
            "Epoch 21/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 324253.7188 - mean_absolute_error: 230.1431 - val_loss: 346694.5000 - val_mean_absolute_error: 239.4364\n",
            "Epoch 22/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 322494.3125 - mean_absolute_error: 229.4623 - val_loss: 342312.0312 - val_mean_absolute_error: 231.1392\n",
            "Epoch 23/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 320559.3438 - mean_absolute_error: 229.1523 - val_loss: 342345.8750 - val_mean_absolute_error: 229.1863\n",
            "Epoch 24/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 318837.8125 - mean_absolute_error: 228.6894 - val_loss: 349333.7500 - val_mean_absolute_error: 250.3130\n",
            "Epoch 25/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 316956.9688 - mean_absolute_error: 228.3519 - val_loss: 343934.3438 - val_mean_absolute_error: 233.3128\n",
            "Epoch 26/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 315530.6562 - mean_absolute_error: 228.1087 - val_loss: 344679.3438 - val_mean_absolute_error: 230.1617\n",
            "Epoch 27/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 314093.2188 - mean_absolute_error: 227.6086 - val_loss: 344274.5312 - val_mean_absolute_error: 230.9732\n",
            "Epoch 28/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 312764.8438 - mean_absolute_error: 227.5653 - val_loss: 348892.4375 - val_mean_absolute_error: 236.9977\n",
            "Epoch 29/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 310659.4688 - mean_absolute_error: 227.1982 - val_loss: 348107.2500 - val_mean_absolute_error: 232.7749\n",
            "Epoch 30/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 308436.4062 - mean_absolute_error: 226.5470 - val_loss: 349471.7812 - val_mean_absolute_error: 236.0706\n",
            "Epoch 31/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 308612.3125 - mean_absolute_error: 226.5074 - val_loss: 346623.6562 - val_mean_absolute_error: 230.0938\n",
            "Epoch 32/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 306280.3750 - mean_absolute_error: 226.1971 - val_loss: 350676.4375 - val_mean_absolute_error: 240.3575\n",
            "Epoch 33/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 304558.0938 - mean_absolute_error: 225.7930 - val_loss: 343143.0938 - val_mean_absolute_error: 229.7189\n",
            "Epoch 34/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 303725.0000 - mean_absolute_error: 225.6578 - val_loss: 345909.0938 - val_mean_absolute_error: 231.9250\n",
            "Epoch 35/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 302237.1562 - mean_absolute_error: 225.1690 - val_loss: 341855.2500 - val_mean_absolute_error: 230.9400\n",
            "Epoch 36/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 301617.8750 - mean_absolute_error: 224.9437 - val_loss: 354391.0938 - val_mean_absolute_error: 234.4990\n",
            "Epoch 37/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 300315.8750 - mean_absolute_error: 225.1171 - val_loss: 342500.2812 - val_mean_absolute_error: 228.5183\n",
            "Epoch 38/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 299291.6562 - mean_absolute_error: 224.8188 - val_loss: 346102.0312 - val_mean_absolute_error: 229.5807\n",
            "Epoch 39/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 297753.5625 - mean_absolute_error: 223.7699 - val_loss: 345668.5625 - val_mean_absolute_error: 231.6477\n",
            "Epoch 40/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 296970.6562 - mean_absolute_error: 224.2022 - val_loss: 346774.6250 - val_mean_absolute_error: 230.2348\n",
            "Epoch 41/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 296020.2188 - mean_absolute_error: 223.9589 - val_loss: 359735.8750 - val_mean_absolute_error: 236.2206\n",
            "Epoch 42/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 293935.3438 - mean_absolute_error: 223.3888 - val_loss: 347992.0312 - val_mean_absolute_error: 230.7554\n",
            "Epoch 43/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 293244.9375 - mean_absolute_error: 223.4517 - val_loss: 344543.3125 - val_mean_absolute_error: 229.9776\n",
            "Epoch 44/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 293111.9688 - mean_absolute_error: 223.0811 - val_loss: 343966.2500 - val_mean_absolute_error: 231.3967\n",
            "Epoch 45/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 291280.4062 - mean_absolute_error: 222.7885 - val_loss: 356149.0938 - val_mean_absolute_error: 231.9240\n",
            "Epoch 46/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 290907.2500 - mean_absolute_error: 222.7007 - val_loss: 350880.9688 - val_mean_absolute_error: 236.9677\n",
            "Epoch 47/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 290266.4062 - mean_absolute_error: 222.3305 - val_loss: 345380.4688 - val_mean_absolute_error: 229.0722\n",
            "Epoch 48/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 287724.3750 - mean_absolute_error: 222.0643 - val_loss: 345903.5938 - val_mean_absolute_error: 229.3102\n",
            "Epoch 49/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 288033.7500 - mean_absolute_error: 222.0414 - val_loss: 351847.8125 - val_mean_absolute_error: 231.0979\n",
            "Epoch 50/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 287947.5000 - mean_absolute_error: 222.2742 - val_loss: 348712.5625 - val_mean_absolute_error: 231.1757\n",
            "Epoch 51/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 286583.4062 - mean_absolute_error: 221.9510 - val_loss: 344423.1562 - val_mean_absolute_error: 229.0654\n",
            "Epoch 52/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 284011.0938 - mean_absolute_error: 221.3889 - val_loss: 353189.7188 - val_mean_absolute_error: 230.8320\n",
            "Epoch 53/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 284083.7500 - mean_absolute_error: 221.1349 - val_loss: 352456.0312 - val_mean_absolute_error: 242.2822\n",
            "Epoch 54/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 283687.3125 - mean_absolute_error: 220.9746 - val_loss: 350555.8438 - val_mean_absolute_error: 231.1356\n",
            "Epoch 55/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 283335.3125 - mean_absolute_error: 221.4340 - val_loss: 353247.7188 - val_mean_absolute_error: 231.1052\n",
            "Epoch 56/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 282388.2188 - mean_absolute_error: 221.1646 - val_loss: 359325.4688 - val_mean_absolute_error: 231.8048\n",
            "Epoch 57/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 282165.3438 - mean_absolute_error: 220.9266 - val_loss: 351369.1250 - val_mean_absolute_error: 236.8942\n",
            "Epoch 58/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 280768.1250 - mean_absolute_error: 220.6006 - val_loss: 353428.1875 - val_mean_absolute_error: 233.3235\n",
            "Epoch 59/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 279137.7188 - mean_absolute_error: 220.3337 - val_loss: 356053.4688 - val_mean_absolute_error: 230.6252\n",
            "Epoch 60/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 279351.2188 - mean_absolute_error: 220.5074 - val_loss: 349053.3125 - val_mean_absolute_error: 229.1649\n",
            "Epoch 61/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 278606.1250 - mean_absolute_error: 220.5492 - val_loss: 357354.8125 - val_mean_absolute_error: 232.1335\n",
            "Epoch 62/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 278580.4688 - mean_absolute_error: 220.5406 - val_loss: 351285.4375 - val_mean_absolute_error: 230.5358\n",
            "Epoch 63/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 276588.7188 - mean_absolute_error: 220.1227 - val_loss: 350945.0312 - val_mean_absolute_error: 231.0927\n",
            "Epoch 64/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 275679.8125 - mean_absolute_error: 220.1303 - val_loss: 345575.8125 - val_mean_absolute_error: 228.9792\n",
            "Epoch 65/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 277565.0625 - mean_absolute_error: 220.4081 - val_loss: 348455.2500 - val_mean_absolute_error: 230.5184\n",
            "Epoch 66/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 273671.6875 - mean_absolute_error: 219.7900 - val_loss: 360206.7500 - val_mean_absolute_error: 231.8456\n",
            "Epoch 67/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 273296.7188 - mean_absolute_error: 219.4756 - val_loss: 370655.0312 - val_mean_absolute_error: 236.6225\n",
            "Epoch 68/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 273724.9375 - mean_absolute_error: 219.8228 - val_loss: 355296.8438 - val_mean_absolute_error: 231.5060\n",
            "Epoch 69/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 272262.5625 - mean_absolute_error: 219.6756 - val_loss: 354167.7812 - val_mean_absolute_error: 230.5173\n",
            "Epoch 70/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 271894.8750 - mean_absolute_error: 219.1869 - val_loss: 358934.3438 - val_mean_absolute_error: 237.4569\n",
            "Epoch 71/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 270666.3750 - mean_absolute_error: 219.0564 - val_loss: 359029.4375 - val_mean_absolute_error: 235.5729\n",
            "Epoch 72/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 270130.4375 - mean_absolute_error: 219.4469 - val_loss: 358897.3125 - val_mean_absolute_error: 232.2323\n",
            "Epoch 73/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 269435.2500 - mean_absolute_error: 218.9404 - val_loss: 353258.7188 - val_mean_absolute_error: 230.8710\n",
            "Epoch 74/1000\n",
            "635/635 [==============================] - 5s 9ms/step - loss: 269775.1562 - mean_absolute_error: 219.1317 - val_loss: 356898.4688 - val_mean_absolute_error: 232.4064\n",
            "Epoch 75/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 268594.0312 - mean_absolute_error: 218.9978 - val_loss: 353528.2188 - val_mean_absolute_error: 230.3860\n",
            "Epoch 76/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 268142.6250 - mean_absolute_error: 219.1828 - val_loss: 356589.1562 - val_mean_absolute_error: 235.9440\n",
            "Epoch 77/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 267556.0938 - mean_absolute_error: 218.6195 - val_loss: 361093.8750 - val_mean_absolute_error: 239.1381\n",
            "Epoch 78/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 267642.7812 - mean_absolute_error: 219.0916 - val_loss: 368445.4062 - val_mean_absolute_error: 234.2960\n",
            "Epoch 79/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 266050.5938 - mean_absolute_error: 218.5242 - val_loss: 357105.8750 - val_mean_absolute_error: 230.9648\n",
            "Epoch 80/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 267174.0625 - mean_absolute_error: 218.9025 - val_loss: 362581.5312 - val_mean_absolute_error: 231.0405\n",
            "Epoch 81/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 264771.3125 - mean_absolute_error: 218.1842 - val_loss: 361032.3750 - val_mean_absolute_error: 231.3083\n",
            "Epoch 82/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 264045.0312 - mean_absolute_error: 218.2853 - val_loss: 370778.7500 - val_mean_absolute_error: 233.7313\n",
            "Epoch 83/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 264477.4688 - mean_absolute_error: 218.6511 - val_loss: 365111.2812 - val_mean_absolute_error: 232.1026\n",
            "Epoch 84/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 263866.5625 - mean_absolute_error: 218.3119 - val_loss: 375346.9375 - val_mean_absolute_error: 236.1430\n",
            "Epoch 85/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 262696.0000 - mean_absolute_error: 217.8315 - val_loss: 361415.5312 - val_mean_absolute_error: 247.3847\n",
            "Epoch 86/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 263198.2500 - mean_absolute_error: 218.0207 - val_loss: 362395.2500 - val_mean_absolute_error: 231.1614\n",
            "Epoch 87/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 263001.3438 - mean_absolute_error: 218.0397 - val_loss: 368317.5938 - val_mean_absolute_error: 234.8947\n",
            "Epoch 88/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 263122.8438 - mean_absolute_error: 218.5932 - val_loss: 358990.1250 - val_mean_absolute_error: 235.8951\n",
            "Epoch 89/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 261319.4531 - mean_absolute_error: 217.9161 - val_loss: 363574.3125 - val_mean_absolute_error: 232.8839\n",
            "Epoch 90/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 260923.9219 - mean_absolute_error: 218.2090 - val_loss: 370309.0625 - val_mean_absolute_error: 234.0200\n",
            "Epoch 91/1000\n",
            "635/635 [==============================] - 4s 6ms/step - loss: 260509.5938 - mean_absolute_error: 217.6550 - val_loss: 362378.8438 - val_mean_absolute_error: 232.1657\n",
            "Epoch 92/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 260754.9844 - mean_absolute_error: 217.8468 - val_loss: 359542.2812 - val_mean_absolute_error: 230.0435\n",
            "Epoch 93/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 259164.2188 - mean_absolute_error: 217.1566 - val_loss: 371881.8125 - val_mean_absolute_error: 232.1777\n",
            "Epoch 94/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 258714.5312 - mean_absolute_error: 217.2532 - val_loss: 374254.1875 - val_mean_absolute_error: 238.9969\n",
            "Epoch 95/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 259166.4219 - mean_absolute_error: 217.4058 - val_loss: 363717.4375 - val_mean_absolute_error: 231.0836\n",
            "Epoch 96/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 257201.5156 - mean_absolute_error: 217.1193 - val_loss: 375170.8750 - val_mean_absolute_error: 241.2012\n",
            "Epoch 97/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 258579.7812 - mean_absolute_error: 217.2856 - val_loss: 363728.4062 - val_mean_absolute_error: 234.0231\n",
            "Epoch 98/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 257869.0625 - mean_absolute_error: 217.2841 - val_loss: 371179.9062 - val_mean_absolute_error: 237.3450\n",
            "Epoch 99/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 256916.8906 - mean_absolute_error: 216.9663 - val_loss: 369392.1250 - val_mean_absolute_error: 234.0954\n",
            "Epoch 100/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 256820.5312 - mean_absolute_error: 217.1302 - val_loss: 387928.5625 - val_mean_absolute_error: 240.3921\n",
            "Epoch 101/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 257383.6562 - mean_absolute_error: 217.3543 - val_loss: 375586.0000 - val_mean_absolute_error: 233.5240\n",
            "Epoch 102/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 256253.9531 - mean_absolute_error: 217.0889 - val_loss: 365473.1562 - val_mean_absolute_error: 231.0622\n",
            "Epoch 103/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 255176.2344 - mean_absolute_error: 216.6218 - val_loss: 384551.2500 - val_mean_absolute_error: 241.3381\n",
            "Epoch 104/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 254323.8125 - mean_absolute_error: 216.6828 - val_loss: 376204.0312 - val_mean_absolute_error: 238.1357\n",
            "Epoch 105/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 254775.6094 - mean_absolute_error: 216.6057 - val_loss: 373255.9688 - val_mean_absolute_error: 236.0175\n",
            "Epoch 106/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 254211.4062 - mean_absolute_error: 216.6725 - val_loss: 368808.6250 - val_mean_absolute_error: 238.2924\n",
            "Epoch 107/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 253564.0625 - mean_absolute_error: 216.5249 - val_loss: 359003.8438 - val_mean_absolute_error: 232.1753\n",
            "Epoch 108/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 254030.2969 - mean_absolute_error: 216.8598 - val_loss: 372176.7812 - val_mean_absolute_error: 237.3138\n",
            "Epoch 109/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 253523.2969 - mean_absolute_error: 216.5771 - val_loss: 373092.5312 - val_mean_absolute_error: 233.6908\n",
            "Epoch 110/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 252668.5938 - mean_absolute_error: 216.4228 - val_loss: 384667.1562 - val_mean_absolute_error: 235.6451\n",
            "Epoch 111/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 252390.7188 - mean_absolute_error: 216.3015 - val_loss: 361818.7812 - val_mean_absolute_error: 232.1913\n",
            "Epoch 112/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 251552.2656 - mean_absolute_error: 216.3586 - val_loss: 386788.1250 - val_mean_absolute_error: 236.8589\n",
            "Epoch 113/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 250633.3281 - mean_absolute_error: 216.0960 - val_loss: 382233.9375 - val_mean_absolute_error: 232.6911\n",
            "Epoch 114/1000\n",
            "635/635 [==============================] - 6s 9ms/step - loss: 249825.5938 - mean_absolute_error: 215.5298 - val_loss: 370213.4375 - val_mean_absolute_error: 234.3833\n",
            "Epoch 115/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 252095.9375 - mean_absolute_error: 216.1138 - val_loss: 376295.1875 - val_mean_absolute_error: 232.1883\n",
            "Epoch 116/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 250991.7031 - mean_absolute_error: 216.1902 - val_loss: 370161.6250 - val_mean_absolute_error: 232.3813\n",
            "Epoch 117/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 250559.9688 - mean_absolute_error: 216.0673 - val_loss: 382058.4062 - val_mean_absolute_error: 239.4738\n",
            "Epoch 118/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 251092.6094 - mean_absolute_error: 216.3270 - val_loss: 369249.7812 - val_mean_absolute_error: 232.3928\n",
            "Epoch 119/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 250643.9219 - mean_absolute_error: 216.0938 - val_loss: 375865.1250 - val_mean_absolute_error: 232.0272\n",
            "Epoch 120/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 249985.4844 - mean_absolute_error: 216.1832 - val_loss: 367765.4375 - val_mean_absolute_error: 231.6180\n",
            "Epoch 121/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 248825.2031 - mean_absolute_error: 215.8436 - val_loss: 380972.2188 - val_mean_absolute_error: 235.0019\n",
            "Epoch 122/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 248981.3750 - mean_absolute_error: 215.7669 - val_loss: 380271.4375 - val_mean_absolute_error: 232.4754\n",
            "Epoch 123/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 247605.3906 - mean_absolute_error: 215.3471 - val_loss: 376008.9688 - val_mean_absolute_error: 232.2870\n",
            "Epoch 124/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 249161.1250 - mean_absolute_error: 215.7394 - val_loss: 380721.6875 - val_mean_absolute_error: 236.0132\n",
            "Epoch 125/1000\n",
            "635/635 [==============================] - 5s 7ms/step - loss: 247423.9219 - mean_absolute_error: 215.3535 - val_loss: 366091.0312 - val_mean_absolute_error: 230.9437\n",
            "Epoch 126/1000\n",
            "635/635 [==============================] - 5s 8ms/step - loss: 247271.6250 - mean_absolute_error: 215.8784 - val_loss: 399905.8750 - val_mean_absolute_error: 238.8470\n",
            "Epoch 127/1000\n",
            "635/635 [==============================] - 4s 7ms/step - loss: 248322.1094 - mean_absolute_error: 215.8209 - val_loss: 392912.0938 - val_mean_absolute_error: 241.7727\n",
            "Epoch 128/1000\n",
            "438/635 [===================>..........] - ETA: 1s - loss: 249471.6719 - mean_absolute_error: 215.9234"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "\n",
        "bitboard_dataset, labels = shuffle(bitboard_dataset, labels, random_state=42)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(bitboard_dataset, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 14, 8, 8, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 14, 8, 8, 1)\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Conv3D(1, (14, 3, 3), activation='relu', input_shape=(14, 8, 8, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=1000, validation_split=0.2)\n",
        "\n",
        "\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Mean Absolute Error:\", mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "id": "lx_ulGlEr0KK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}