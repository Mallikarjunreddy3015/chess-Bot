{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXu6D-nv_Z3N",
        "outputId": "a43cb4cb-998d-4c34-f6a5-8f503e059bb2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441193998,
          "user_tz": -330,
          "elapsed": 15331,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Obtaining dependency information for chess<2,>=1 from https://files.pythonhosted.org/packages/d6/d8/15cfcb738d2518daf04d34b23419bd359cbd8e09da50778ebac521774fc8/chess-1.10.0-py3-none-any.whl.metadata\n",
            "  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess, python-chess\n",
            "Successfully installed chess-1.10.0 python-chess-1.999\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install python-chess\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import chess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FeCoY3TqrFPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faddcb4f-926e-499d-eaf3-31544d660010",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441223918,
          "user_tz": -330,
          "elapsed": 14756,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading chessfendataset.zip to /content\n",
            " 99% 143M/144M [00:08<00:00, 25.0MB/s]\n",
            "100% 144M/144M [00:08<00:00, 18.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "!kaggle datasets download -d mallikarjunreddy3015/chessfendataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Get system memory information\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"Total RAM: {memory.total / (1024 ** 3):.2f} GB\")\n",
        "print(f\"Used RAM: {memory.used / (1024 ** 3):.2f} GB\")\n",
        "print(f\"Free RAM: {memory.free / (1024 ** 3):.2f} GB\")\n"
      ],
      "metadata": {
        "id": "_Kw8L5mmaSlc",
        "outputId": "b58431b8-e716-46a1-f747-f9ab51e0992d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441231585,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 58.87 GB\n",
            "Used RAM: 1.29 GB\n",
            "Free RAM: 55.76 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'your-dataset.zip' with the actual zip file name\n",
        "with zipfile.ZipFile('/content/chessfendataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/chessfendataset')\n"
      ],
      "metadata": {
        "id": "IXadynQ0WgkB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441231585,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bPvv15KtoS7k",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441247039,
          "user_tz": -330,
          "elapsed": 15456,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv('/content/chessfendataset/chessData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkzx33u0Snt_",
        "outputId": "65970dd8-aa20-4e9b-bec6-3b916d210d1a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441247039,
          "user_tz": -330,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct  4 17:40:46 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1yQdZKrXsNU3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441256155,
          "user_tz": -330,
          "elapsed": 2900,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "dataframe.head()\n",
        "d=dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XQdVPluX9Ngk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441273413,
          "user_tz": -330,
          "elapsed": 17260,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "d.shape\n",
        "d1=d.iloc[0:5000000 ,:]\n",
        "d1.shape\n",
        "d1 = d1[~d1['Evaluation'].str.contains('\\ufeff|#', na=False)]\n",
        "d1['Evaluation'] = pd.to_numeric(d1['Evaluation'].str.replace('[^\\d.-]', '', regex=True), errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Evt8Knj7KO-_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696441278128,
          "user_tz": -330,
          "elapsed": 13,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "d1['Scaled_Evaluation'] = 1000 * (2 * (d1['Evaluation'] +7000) / (14000) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mBXGrD1GbmOd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696486998352,
          "user_tz": -330,
          "elapsed": 45713529,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "def create_bitboard(fen):\n",
        "    i+1\n",
        "    # Setting up the piece values\n",
        "    piece_values = {\n",
        "        'P': 11, 'p': -11, 'N': 44, 'n': -44, 'B': 33, 'b': -33, 'R': 55,\n",
        "        'r': -55, 'Q': 99, 'q': -99, 'K': 110, 'k': -110\n",
        "    }\n",
        "\n",
        "    # Mapping piece symbols to bitboard layers\n",
        "    piece_to_layer = {\n",
        "        'P': 0, 'p': 1, 'N': 2, 'n': 3, 'B': 4, 'b': 5, 'R': 6, 'r': 7, 'Q': 8,\n",
        "        'q': 9, 'K': 10, 'k': 11\n",
        "    }\n",
        "\n",
        "    # Create an empty bitboard of shape (12, 8, 8) using numpy\n",
        "    en_passant_layer = 12\n",
        "    white_values_layer = 13\n",
        "    black_values_layer = 14\n",
        "\n",
        "    bitboard = np.zeros((15, 8, 8))\n",
        "\n",
        "    board = chess.Board(fen)\n",
        "    if board.ep_square is not None:\n",
        "        rank, file = divmod(board.ep_square, 8)\n",
        "        bitboard[en_passant_layer][rank][file] = 1 if board.turn == chess.WHITE else -1\n",
        "    computed_moves = {}\n",
        "\n",
        "    for piece_type, piece_value in piece_values.items():\n",
        "        layer = piece_to_layer[piece_type]\n",
        "\n",
        "        if piece_type not in computed_moves:\n",
        "            valid_moves = set()\n",
        "            empty_board_moves = set()\n",
        "            for square in chess.SQUARES:\n",
        "                piece = board.piece_at(square)\n",
        "                if piece and piece.symbol() == piece_type:\n",
        "                    # Generate moves for both colors irrespective of turn\n",
        "                    board.turn = chess.WHITE\n",
        "                    moves_white = [move for move in board.legal_moves if move.from_square == square]\n",
        "                    board.turn = chess.BLACK\n",
        "                    moves_black = [move for move in board.legal_moves if move.from_square == square]\n",
        "                    valid_moves.update([move.to_square for move in moves_white])\n",
        "                    valid_moves.update([move.to_square for move in moves_black])\n",
        "\n",
        "                    empty_board = chess.Board()\n",
        "                    empty_board.clear()\n",
        "                    empty_board.set_piece_at(square, piece)\n",
        "                    # Generate moves for both colors irrespective of turn on the empty board\n",
        "                    empty_board.turn = chess.WHITE\n",
        "                    empty_moves_white = [move for move in empty_board.generate_legal_moves(from_mask=chess.BB_SQUARES[square])]\n",
        "                    empty_board.turn = chess.BLACK\n",
        "                    empty_moves_black = [move for move in empty_board.generate_legal_moves(from_mask=chess.BB_SQUARES[square])]\n",
        "                    empty_board_moves.update([move.to_square for move in empty_moves_white])\n",
        "                    empty_board_moves.update([move.to_square for move in empty_moves_black])\n",
        "\n",
        "            computed_moves[piece_type] = (valid_moves, empty_board_moves)\n",
        "\n",
        "        valid_moves, empty_board_moves = computed_moves[piece_type]\n",
        "\n",
        "        for square in chess.SQUARES:\n",
        "            rank, file = divmod(square, 8)\n",
        "            piece = board.piece_at(square)\n",
        "            if piece:\n",
        "                if piece.color == chess.WHITE:\n",
        "                    bitboard[white_values_layer][rank][file] = piece_values[piece.symbol()]\n",
        "                else:\n",
        "                    bitboard[black_values_layer][rank][file] = piece_values[piece.symbol()]\n",
        "            if piece and piece.symbol() == piece_type:\n",
        "                bitboard[layer][rank][file] = piece_value\n",
        "            elif square in valid_moves:\n",
        "                bitboard[layer][rank][file] = piece_value / 11\n",
        "            elif square in empty_board_moves:\n",
        "                bitboard[layer][rank][file] = piece_value / 22\n",
        "        if i%100000==0:\n",
        "           print(i)\n",
        "        return bitboard\n",
        "\n",
        "bitboard_dataset = [create_bitboard(fen) for fen in np.array(d1['FEN'])]\n",
        "# print(generate_bitboard_with_moves(d1[\"FEN\"][1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFSsXYpsWrou",
        "outputId": "755b6999-18bb-43e0-f2ca-6caa8c5539f0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696486998352,
          "user_tz": -330,
          "elapsed": 14,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [  11.    11.     0.     0.     0.     0.    11.    11. ]\n",
            "  [   1.     1.     0.     0.     0.     0.     1.     1. ]\n",
            "  [   1.     0.5    0.    11.     0.    11.     1.     1. ]\n",
            "  [   0.     0.     0.     0.5   11.     1.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.5    1.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.    -0.5    0.     0.     0.     0. ]\n",
            "  [  -1.    -0.5    0.   -11.    -1.    -1.    -1.    -1. ]\n",
            "  [  -1.    -0.5    0.     0.   -11.   -11.    -1.    -1. ]\n",
            "  [ -11.   -11.     0.     0.     0.     0.   -11.   -11. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     4.     0.     2.     0.     4.     0. ]\n",
            "  [   0.     0.     0.     2.    44.     0.     0.     2. ]\n",
            "  [   0.     0.     4.     0.     0.    44.     4.     0. ]\n",
            "  [   0.     0.     0.     2.     0.     2.     0.     4. ]\n",
            "  [   0.     0.     0.     0.     2.     0.     4.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.    -2.     0.    -4.     0.     0.     0.     0. ]\n",
            "  [  -4.     0.    -4.     0.    -4.     0.     0.     0. ]\n",
            "  [   0.    -2.   -44.     0.     0.    -2.     0.     0. ]\n",
            "  [  -2.     0.     0.   -44.    -4.     0.     0.     0. ]\n",
            "  [   0.    -4.     0.    -4.     0.    -4.     0.     0. ]]\n",
            "\n",
            " [[   0.     3.     1.5    0.     1.5    1.5    0.     0. ]\n",
            "  [   0.     0.     3.    33.     1.5    0.     0.     0. ]\n",
            "  [   0.     0.     3.    33.     1.5    0.     0.     0. ]\n",
            "  [   0.     3.     3.     0.     3.     1.5    0.     0. ]\n",
            "  [   1.5    3.     0.     0.     0.     3.     1.5    0. ]\n",
            "  [   3.     0.     0.     0.     0.     0.     3.     1.5]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     3. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.    -1.5    0.     0.     0. ]\n",
            "  [   0.     0.     0.    -3.     0.     0.     0.     0. ]\n",
            "  [  -3.     0.    -3.     0.     0.     0.     0.    -1.5]\n",
            "  [   0.   -33.     0.     0.     0.     0.    -1.5    0. ]\n",
            "  [  -3.     0.    -3.     0.     0.    -1.5    0.     0. ]\n",
            "  [  -1.5    0.     0.    -3.    -1.5    0.     0.     0. ]\n",
            "  [   0.    -1.5    0.    -1.5   -3.     0.     0.     0. ]\n",
            "  [   0.     0.   -33.     0.     0.    -3.     0.     0. ]]\n",
            "\n",
            " [[  55.     5.     5.     2.5    2.5    5.     5.    55. ]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]\n",
            "  [   2.5    0.     0.     0.     0.     0.     0.     2.5]]\n",
            "\n",
            " [[  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [  -2.5    0.     0.     0.     0.     0.     0.    -2.5]\n",
            "  [ -55.    -5.    -2.5   -2.5   -2.5   -5.    -5.   -55. ]]\n",
            "\n",
            " [[   4.5    9.     9.    99.     4.5    4.5    4.5    4.5]\n",
            "  [   0.     0.     9.     4.5    4.5    0.     0.     0. ]\n",
            "  [   0.     9.     0.     4.5    0.     4.5    0.     0. ]\n",
            "  [   9.     0.     0.     4.5    0.     0.     4.5    0. ]\n",
            "  [   0.     0.     0.     4.5    0.     0.     0.     4.5]\n",
            "  [   0.     0.     0.     4.5    0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     4.5    0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     4.5    0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.    -4.5    0.     0.     0.     0.    -4.5    0. ]\n",
            "  [   0.    -4.5    0.     0.     0.    -4.5    0.     0. ]\n",
            "  [   0.    -4.5    0.     0.    -4.5    0.     0.     0. ]\n",
            "  [   0.    -4.5    0.    -9.     0.     0.     0.     0. ]\n",
            "  [  -9.    -9.    -9.     0.     0.     0.     0.     0. ]\n",
            "  [  -9.   -99.    -4.5   -4.5   -4.5   -4.5   -4.5   -4.5]\n",
            "  [  -4.5   -4.5   -9.     0.     0.     0.     0.     0. ]\n",
            "  [   0.    -4.5    0.    -9.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     5.   110.    10.    10.     0. ]\n",
            "  [   0.     0.     0.     5.     5.    10.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.    -5.   -10.   -10.     0.     0. ]\n",
            "  [   0.     0.     0.   -10.  -110.   -10.   -10.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[  55.     0.     0.    99.   110.     0.     0.    55. ]\n",
            "  [  11.    11.     0.    33.    44.     0.    11.    11. ]\n",
            "  [   0.     0.     0.    33.     0.    44.     0.     0. ]\n",
            "  [   0.     0.     0.    11.     0.    11.     0.     0. ]\n",
            "  [   0.     0.     0.     0.    11.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]]\n",
            "\n",
            " [[   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.   -33.     0.     0.     0.     0.     0.     0. ]\n",
            "  [   0.     0.     0.   -11.     0.     0.     0.     0. ]\n",
            "  [   0.   -99.   -44.     0.   -11.   -11.     0.     0. ]\n",
            "  [ -11.   -11.     0.   -44.     0.     0.   -11.   -11. ]\n",
            "  [ -55.     0.   -33.     0.  -110.     0.     0.   -55. ]]]\n"
          ]
        }
      ],
      "source": [
        "print(bitboard_dataset[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L54mHai3qOOI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696486998353,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# labels=d1['Evaluation']\n",
        "labels=d1['Scaled_Evaluation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnfn9WPEni1p"
      },
      "outputs": [],
      "source": [
        "np.save('/content/bitboard_dataset_5M.npy', bitboard_dataset)\n",
        "np.save('/content/labels_dataset_5M.npy', labels)\n",
        "\n",
        "# bitboard_dataset=np.load(\"/content/chess-numpy-dataset/bitboard_dataset_1M.npy\")\n",
        "# labels=np.load(\"/content/chess-numpy-dataset/labels_dataset.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage\n",
        "import os\n",
        "\n",
        "# Replace 'path/to/service-account-key.json' with the path to your service account key file\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/gleaming-modem-400906-3780658b0f47.json'\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "# Replace 'your-bucket-name' with the name of your Google Cloud Storage bucket\n",
        "bucket_name = 'chess_data_all'\n",
        "\n",
        "# Save the array to a binary file\n",
        "file_path = '/content/labels_dataset_5M.npy'\n",
        "\n",
        "# Create a Google Cloud Storage client\n",
        "client = storage.Client()\n",
        "\n",
        "# Specify the destination blob (file) in your bucket\n",
        "blob_name = 'labels_dataset_5M.npy'\n",
        "\n",
        "# Upload the file to the bucket\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "blob.upload_from_filename(file_path)\n",
        "\n",
        "print(f\"File uploaded to: gs://{bucket_name}/{blob_name}\")\n"
      ],
      "metadata": {
        "id": "Ma1A_N8GXb1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y9qEfiSErKrv",
        "outputId": "dbc85ec6-c2ec-4c1b-c317-6478a9b221f1",
        "executionInfo": {
          "status": "error",
          "timestamp": 1696367463220,
          "user_tz": -330,
          "elapsed": 1656195,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 15, 8, 8, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv3d (Conv3D)             (None, 1, 1, 1, 8)           7688      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv3d_1 (Conv3D)           (None, 1, 4, 4, 4)           1504      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv3d_2 (Conv3D)           (None, 15, 1, 1, 8)          520       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 8)                    0         ['conv3d[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 64)                   0         ['conv3d_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 120)                  0         ['conv3d_2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 192)                  0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]',           \n",
            "                                                                     'flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 192)                  768       ['concatenate[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 192)                  0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   12352     ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 64)                   256       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 32)                   2080      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32)                   128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 16)                   528       ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 16)                   64        ['dense_2[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    17        ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25905 (101.19 KB)\n",
            "Trainable params: 25297 (98.82 KB)\n",
            "Non-trainable params: 608 (2.38 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "710/710 [==============================] - 27s 18ms/step - loss: 11598.2471 - mean_absolute_error: 39.7277 - val_loss: 10009.8848 - val_mean_absolute_error: 37.6516\n",
            "Epoch 2/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 8723.1670 - mean_absolute_error: 36.2156 - val_loss: 8242.5762 - val_mean_absolute_error: 36.8529\n",
            "Epoch 3/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7917.7505 - mean_absolute_error: 35.8287 - val_loss: 7965.5649 - val_mean_absolute_error: 36.1720\n",
            "Epoch 4/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7666.8560 - mean_absolute_error: 35.4067 - val_loss: 7820.0630 - val_mean_absolute_error: 35.7737\n",
            "Epoch 5/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7513.0762 - mean_absolute_error: 35.0576 - val_loss: 7720.5273 - val_mean_absolute_error: 35.0615\n",
            "Epoch 6/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7397.0171 - mean_absolute_error: 34.7844 - val_loss: 7629.4058 - val_mean_absolute_error: 34.8824\n",
            "Epoch 7/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7309.1772 - mean_absolute_error: 34.5632 - val_loss: 7553.0908 - val_mean_absolute_error: 34.7966\n",
            "Epoch 8/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7227.0752 - mean_absolute_error: 34.3824 - val_loss: 7551.3545 - val_mean_absolute_error: 35.2751\n",
            "Epoch 9/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7169.0825 - mean_absolute_error: 34.2430 - val_loss: 7517.7896 - val_mean_absolute_error: 34.5396\n",
            "Epoch 10/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7110.2534 - mean_absolute_error: 34.1092 - val_loss: 7488.9917 - val_mean_absolute_error: 34.2308\n",
            "Epoch 11/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7056.0854 - mean_absolute_error: 33.9672 - val_loss: 7438.5317 - val_mean_absolute_error: 34.4757\n",
            "Epoch 12/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7015.4893 - mean_absolute_error: 33.8812 - val_loss: 7429.3730 - val_mean_absolute_error: 34.8018\n",
            "Epoch 13/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6979.5117 - mean_absolute_error: 33.7982 - val_loss: 7437.7666 - val_mean_absolute_error: 34.5548\n",
            "Epoch 14/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6939.0625 - mean_absolute_error: 33.7065 - val_loss: 7391.2466 - val_mean_absolute_error: 34.2318\n",
            "Epoch 15/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6904.5103 - mean_absolute_error: 33.6148 - val_loss: 7335.3481 - val_mean_absolute_error: 34.0953\n",
            "Epoch 16/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6878.6133 - mean_absolute_error: 33.5798 - val_loss: 7300.5591 - val_mean_absolute_error: 34.0986\n",
            "Epoch 17/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6847.8149 - mean_absolute_error: 33.5004 - val_loss: 7334.0405 - val_mean_absolute_error: 34.1852\n",
            "Epoch 18/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6820.9443 - mean_absolute_error: 33.4431 - val_loss: 7314.1753 - val_mean_absolute_error: 34.3854\n",
            "Epoch 19/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6799.7148 - mean_absolute_error: 33.3927 - val_loss: 7302.6221 - val_mean_absolute_error: 34.4626\n",
            "Epoch 20/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6769.6250 - mean_absolute_error: 33.3182 - val_loss: 7264.0308 - val_mean_absolute_error: 34.3261\n",
            "Epoch 21/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6754.1182 - mean_absolute_error: 33.2970 - val_loss: 7222.5273 - val_mean_absolute_error: 34.0668\n",
            "Epoch 22/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6732.8447 - mean_absolute_error: 33.2270 - val_loss: 7223.4937 - val_mean_absolute_error: 34.3724\n",
            "Epoch 23/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6717.1577 - mean_absolute_error: 33.1954 - val_loss: 7213.4219 - val_mean_absolute_error: 33.9551\n",
            "Epoch 24/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6694.5972 - mean_absolute_error: 33.1527 - val_loss: 7236.1001 - val_mean_absolute_error: 34.1175\n",
            "Epoch 25/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6684.2212 - mean_absolute_error: 33.1157 - val_loss: 7264.2925 - val_mean_absolute_error: 34.1023\n",
            "Epoch 26/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6668.8545 - mean_absolute_error: 33.0681 - val_loss: 7173.4844 - val_mean_absolute_error: 33.7323\n",
            "Epoch 27/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6652.2778 - mean_absolute_error: 33.0448 - val_loss: 7152.3916 - val_mean_absolute_error: 33.4587\n",
            "Epoch 28/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6641.8418 - mean_absolute_error: 33.0029 - val_loss: 7178.9473 - val_mean_absolute_error: 33.6648\n",
            "Epoch 29/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6624.1582 - mean_absolute_error: 32.9552 - val_loss: 7166.7598 - val_mean_absolute_error: 33.5878\n",
            "Epoch 30/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6610.3271 - mean_absolute_error: 32.9202 - val_loss: 7158.9155 - val_mean_absolute_error: 33.5043\n",
            "Epoch 31/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6598.5552 - mean_absolute_error: 32.8899 - val_loss: 7134.0210 - val_mean_absolute_error: 33.5656\n",
            "Epoch 32/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6589.7021 - mean_absolute_error: 32.8598 - val_loss: 7149.4111 - val_mean_absolute_error: 34.0559\n",
            "Epoch 33/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6577.9258 - mean_absolute_error: 32.8368 - val_loss: 7100.3271 - val_mean_absolute_error: 33.4431\n",
            "Epoch 34/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6565.1704 - mean_absolute_error: 32.7867 - val_loss: 7155.1533 - val_mean_absolute_error: 33.9908\n",
            "Epoch 35/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6551.2095 - mean_absolute_error: 32.7603 - val_loss: 7188.6353 - val_mean_absolute_error: 33.6035\n",
            "Epoch 36/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6542.7227 - mean_absolute_error: 32.7401 - val_loss: 7130.0210 - val_mean_absolute_error: 33.6221\n",
            "Epoch 37/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6535.2568 - mean_absolute_error: 32.7283 - val_loss: 7135.8540 - val_mean_absolute_error: 33.4115\n",
            "Epoch 38/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6525.3115 - mean_absolute_error: 32.6762 - val_loss: 7102.2856 - val_mean_absolute_error: 33.3553\n",
            "Epoch 39/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6511.6445 - mean_absolute_error: 32.6454 - val_loss: 7206.1118 - val_mean_absolute_error: 33.7309\n",
            "Epoch 40/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6502.0317 - mean_absolute_error: 32.6173 - val_loss: 7133.8325 - val_mean_absolute_error: 33.5224\n",
            "Epoch 41/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6499.0425 - mean_absolute_error: 32.6117 - val_loss: 7128.7642 - val_mean_absolute_error: 33.8432\n",
            "Epoch 42/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6487.4976 - mean_absolute_error: 32.5768 - val_loss: 7122.4790 - val_mean_absolute_error: 33.6408\n",
            "Epoch 43/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6473.7021 - mean_absolute_error: 32.5477 - val_loss: 7091.4355 - val_mean_absolute_error: 33.2541\n",
            "Epoch 44/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6473.1768 - mean_absolute_error: 32.5355 - val_loss: 7080.8652 - val_mean_absolute_error: 33.3298\n",
            "Epoch 45/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6461.7129 - mean_absolute_error: 32.5191 - val_loss: 7096.0522 - val_mean_absolute_error: 33.5008\n",
            "Epoch 46/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6452.6494 - mean_absolute_error: 32.5032 - val_loss: 7099.4717 - val_mean_absolute_error: 33.5263\n",
            "Epoch 47/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6446.6606 - mean_absolute_error: 32.4802 - val_loss: 7110.6333 - val_mean_absolute_error: 34.0278\n",
            "Epoch 48/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6448.2310 - mean_absolute_error: 32.4742 - val_loss: 7075.8755 - val_mean_absolute_error: 33.6372\n",
            "Epoch 49/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6439.6030 - mean_absolute_error: 32.4630 - val_loss: 7065.5728 - val_mean_absolute_error: 33.0631\n",
            "Epoch 50/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6422.5942 - mean_absolute_error: 32.4273 - val_loss: 7133.1074 - val_mean_absolute_error: 33.8785\n",
            "Epoch 51/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6417.4673 - mean_absolute_error: 32.4152 - val_loss: 7135.1304 - val_mean_absolute_error: 33.7406\n",
            "Epoch 52/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6413.7812 - mean_absolute_error: 32.4111 - val_loss: 7132.0254 - val_mean_absolute_error: 33.5363\n",
            "Epoch 53/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6408.2808 - mean_absolute_error: 32.3992 - val_loss: 7206.8857 - val_mean_absolute_error: 33.5327\n",
            "Epoch 54/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6406.1748 - mean_absolute_error: 32.3765 - val_loss: 7119.5063 - val_mean_absolute_error: 33.6447\n",
            "Epoch 55/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6397.7393 - mean_absolute_error: 32.3626 - val_loss: 7052.4243 - val_mean_absolute_error: 33.0046\n",
            "Epoch 56/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6392.7046 - mean_absolute_error: 32.3515 - val_loss: 7084.8662 - val_mean_absolute_error: 33.0279\n",
            "Epoch 57/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6382.9424 - mean_absolute_error: 32.3321 - val_loss: 7064.5376 - val_mean_absolute_error: 33.1153\n",
            "Epoch 58/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6392.4829 - mean_absolute_error: 32.3570 - val_loss: 7085.9614 - val_mean_absolute_error: 33.6456\n",
            "Epoch 59/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6375.9526 - mean_absolute_error: 32.3163 - val_loss: 7106.2656 - val_mean_absolute_error: 33.6574\n",
            "Epoch 60/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6370.4580 - mean_absolute_error: 32.3026 - val_loss: 7069.9121 - val_mean_absolute_error: 33.0089\n",
            "Epoch 61/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6370.7520 - mean_absolute_error: 32.2908 - val_loss: 7110.6748 - val_mean_absolute_error: 33.4709\n",
            "Epoch 62/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6365.5317 - mean_absolute_error: 32.2858 - val_loss: 7074.0723 - val_mean_absolute_error: 33.3263\n",
            "Epoch 63/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6356.3569 - mean_absolute_error: 32.2605 - val_loss: 7055.3672 - val_mean_absolute_error: 33.2198\n",
            "Epoch 64/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6356.6860 - mean_absolute_error: 32.2705 - val_loss: 7097.5327 - val_mean_absolute_error: 33.3909\n",
            "Epoch 65/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6353.6040 - mean_absolute_error: 32.2519 - val_loss: 7068.9609 - val_mean_absolute_error: 33.5294\n",
            "Epoch 66/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6344.9878 - mean_absolute_error: 32.2499 - val_loss: 7095.5078 - val_mean_absolute_error: 33.2397\n",
            "Epoch 67/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6341.7832 - mean_absolute_error: 32.2412 - val_loss: 7112.8203 - val_mean_absolute_error: 33.1763\n",
            "Epoch 68/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6333.6011 - mean_absolute_error: 32.2297 - val_loss: 7091.6172 - val_mean_absolute_error: 33.4676\n",
            "Epoch 69/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6335.9761 - mean_absolute_error: 32.2231 - val_loss: 7100.1489 - val_mean_absolute_error: 33.4582\n",
            "Epoch 70/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6328.9180 - mean_absolute_error: 32.2035 - val_loss: 7043.0029 - val_mean_absolute_error: 33.1457\n",
            "Epoch 71/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6328.6074 - mean_absolute_error: 32.2118 - val_loss: 7083.9409 - val_mean_absolute_error: 33.2415\n",
            "Epoch 72/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6326.3086 - mean_absolute_error: 32.1895 - val_loss: 7035.6870 - val_mean_absolute_error: 33.1099\n",
            "Epoch 73/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6312.0181 - mean_absolute_error: 32.1704 - val_loss: 7092.1772 - val_mean_absolute_error: 33.9998\n",
            "Epoch 74/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6318.5854 - mean_absolute_error: 32.1778 - val_loss: 7069.1831 - val_mean_absolute_error: 33.5340\n",
            "Epoch 75/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6306.1001 - mean_absolute_error: 32.1534 - val_loss: 7065.2729 - val_mean_absolute_error: 33.2958\n",
            "Epoch 76/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6307.4058 - mean_absolute_error: 32.1592 - val_loss: 7093.8979 - val_mean_absolute_error: 32.9722\n",
            "Epoch 77/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6308.1230 - mean_absolute_error: 32.1508 - val_loss: 7065.2695 - val_mean_absolute_error: 33.3138\n",
            "Epoch 78/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6297.5576 - mean_absolute_error: 32.1332 - val_loss: 7124.8823 - val_mean_absolute_error: 33.7939\n",
            "Epoch 79/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6291.6157 - mean_absolute_error: 32.1242 - val_loss: 7085.8145 - val_mean_absolute_error: 33.2756\n",
            "Epoch 80/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6292.3135 - mean_absolute_error: 32.1114 - val_loss: 7090.9062 - val_mean_absolute_error: 33.6570\n",
            "Epoch 81/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6292.3633 - mean_absolute_error: 32.1184 - val_loss: 7057.0557 - val_mean_absolute_error: 33.4665\n",
            "Epoch 82/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6287.6099 - mean_absolute_error: 32.1091 - val_loss: 7099.8965 - val_mean_absolute_error: 33.6233\n",
            "Epoch 83/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6284.1621 - mean_absolute_error: 32.1054 - val_loss: 7081.8794 - val_mean_absolute_error: 32.9196\n",
            "Epoch 84/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6284.7437 - mean_absolute_error: 32.1047 - val_loss: 7078.7280 - val_mean_absolute_error: 33.2607\n",
            "Epoch 85/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6274.0352 - mean_absolute_error: 32.0711 - val_loss: 7085.9453 - val_mean_absolute_error: 34.1367\n",
            "Epoch 86/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6269.4023 - mean_absolute_error: 32.0728 - val_loss: 7145.8062 - val_mean_absolute_error: 33.7252\n",
            "Epoch 87/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6269.4922 - mean_absolute_error: 32.0727 - val_loss: 7106.2515 - val_mean_absolute_error: 33.2150\n",
            "Epoch 88/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6269.6665 - mean_absolute_error: 32.0770 - val_loss: 7047.4507 - val_mean_absolute_error: 32.9875\n",
            "Epoch 89/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6258.6167 - mean_absolute_error: 32.0472 - val_loss: 7127.1118 - val_mean_absolute_error: 33.7178\n",
            "Epoch 90/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6261.7891 - mean_absolute_error: 32.0553 - val_loss: 7071.1479 - val_mean_absolute_error: 32.9661\n",
            "Epoch 91/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6255.7969 - mean_absolute_error: 32.0404 - val_loss: 7090.7876 - val_mean_absolute_error: 33.4523\n",
            "Epoch 92/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6255.9375 - mean_absolute_error: 32.0378 - val_loss: 7090.8716 - val_mean_absolute_error: 33.6794\n",
            "Epoch 93/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6249.2314 - mean_absolute_error: 32.0268 - val_loss: 7097.0269 - val_mean_absolute_error: 33.6248\n",
            "Epoch 94/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6252.9287 - mean_absolute_error: 32.0303 - val_loss: 7145.2119 - val_mean_absolute_error: 34.1181\n",
            "Epoch 95/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6248.2588 - mean_absolute_error: 32.0257 - val_loss: 7126.0854 - val_mean_absolute_error: 33.8341\n",
            "Epoch 96/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6245.0654 - mean_absolute_error: 32.0085 - val_loss: 7141.7202 - val_mean_absolute_error: 33.7748\n",
            "Epoch 97/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6243.0215 - mean_absolute_error: 32.0167 - val_loss: 7069.5469 - val_mean_absolute_error: 33.5906\n",
            "Epoch 98/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6242.3599 - mean_absolute_error: 32.0029 - val_loss: 7065.6870 - val_mean_absolute_error: 33.2137\n",
            "Epoch 99/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6233.8203 - mean_absolute_error: 31.9931 - val_loss: 7096.2188 - val_mean_absolute_error: 33.1804\n",
            "Epoch 100/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6235.8643 - mean_absolute_error: 31.9964 - val_loss: 7130.6387 - val_mean_absolute_error: 33.9511\n",
            "Epoch 101/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6227.5264 - mean_absolute_error: 31.9763 - val_loss: 7131.4844 - val_mean_absolute_error: 33.8614\n",
            "Epoch 102/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6236.3550 - mean_absolute_error: 31.9932 - val_loss: 7137.2295 - val_mean_absolute_error: 34.5793\n",
            "Epoch 103/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6229.9956 - mean_absolute_error: 31.9888 - val_loss: 7090.7773 - val_mean_absolute_error: 33.1110\n",
            "Epoch 104/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6219.7480 - mean_absolute_error: 31.9619 - val_loss: 7139.6670 - val_mean_absolute_error: 33.9914\n",
            "Epoch 105/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6224.2109 - mean_absolute_error: 31.9724 - val_loss: 7078.2827 - val_mean_absolute_error: 32.9456\n",
            "Epoch 106/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6219.0781 - mean_absolute_error: 31.9534 - val_loss: 7093.4917 - val_mean_absolute_error: 33.1052\n",
            "Epoch 107/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6216.1592 - mean_absolute_error: 31.9557 - val_loss: 7104.1152 - val_mean_absolute_error: 33.1989\n",
            "Epoch 108/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6215.8291 - mean_absolute_error: 31.9553 - val_loss: 7060.8569 - val_mean_absolute_error: 33.1132\n",
            "Epoch 109/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6217.4038 - mean_absolute_error: 31.9506 - val_loss: 7058.1841 - val_mean_absolute_error: 32.9905\n",
            "Epoch 110/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6214.4678 - mean_absolute_error: 31.9538 - val_loss: 7066.6719 - val_mean_absolute_error: 33.0093\n",
            "Epoch 111/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6209.9009 - mean_absolute_error: 31.9391 - val_loss: 7071.4741 - val_mean_absolute_error: 33.1201\n",
            "Epoch 112/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6204.2866 - mean_absolute_error: 31.9270 - val_loss: 7104.3120 - val_mean_absolute_error: 33.2767\n",
            "Epoch 113/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6205.8633 - mean_absolute_error: 31.9199 - val_loss: 7128.5718 - val_mean_absolute_error: 33.7951\n",
            "Epoch 114/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6201.5996 - mean_absolute_error: 31.9269 - val_loss: 7043.0068 - val_mean_absolute_error: 33.0891\n",
            "Epoch 115/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6203.8062 - mean_absolute_error: 31.9273 - val_loss: 7143.7954 - val_mean_absolute_error: 34.0167\n",
            "Epoch 116/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6197.8730 - mean_absolute_error: 31.9189 - val_loss: 7136.3960 - val_mean_absolute_error: 34.3952\n",
            "Epoch 117/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6199.3184 - mean_absolute_error: 31.9254 - val_loss: 7091.1221 - val_mean_absolute_error: 32.9182\n",
            "Epoch 118/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6197.0088 - mean_absolute_error: 31.9156 - val_loss: 7154.7705 - val_mean_absolute_error: 33.3842\n",
            "Epoch 119/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6197.5049 - mean_absolute_error: 31.9145 - val_loss: 7219.9194 - val_mean_absolute_error: 35.9403\n",
            "Epoch 120/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6187.9312 - mean_absolute_error: 31.9112 - val_loss: 7163.8574 - val_mean_absolute_error: 33.0890\n",
            "Epoch 121/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6185.4351 - mean_absolute_error: 31.8937 - val_loss: 7069.2319 - val_mean_absolute_error: 32.9200\n",
            "Epoch 122/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6188.1123 - mean_absolute_error: 31.9001 - val_loss: 7100.8066 - val_mean_absolute_error: 33.3007\n",
            "Epoch 123/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6179.6035 - mean_absolute_error: 31.8823 - val_loss: 7133.2510 - val_mean_absolute_error: 34.1864\n",
            "Epoch 124/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6184.8530 - mean_absolute_error: 31.9014 - val_loss: 7145.0908 - val_mean_absolute_error: 34.2031\n",
            "Epoch 125/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6182.4238 - mean_absolute_error: 31.8905 - val_loss: 7070.1699 - val_mean_absolute_error: 32.9342\n",
            "Epoch 126/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6180.0000 - mean_absolute_error: 31.8729 - val_loss: 7130.5244 - val_mean_absolute_error: 33.8655\n",
            "Epoch 127/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6180.5122 - mean_absolute_error: 31.8866 - val_loss: 7086.5376 - val_mean_absolute_error: 32.8527\n",
            "Epoch 128/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6174.4829 - mean_absolute_error: 31.8739 - val_loss: 7076.1235 - val_mean_absolute_error: 32.9624\n",
            "Epoch 129/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6176.6943 - mean_absolute_error: 31.8693 - val_loss: 7107.1138 - val_mean_absolute_error: 33.1918\n",
            "Epoch 130/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6179.1592 - mean_absolute_error: 31.8914 - val_loss: 7072.5747 - val_mean_absolute_error: 33.2057\n",
            "Epoch 131/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6173.0088 - mean_absolute_error: 31.8710 - val_loss: 7133.2861 - val_mean_absolute_error: 34.0721\n",
            "Epoch 132/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6172.2695 - mean_absolute_error: 31.8594 - val_loss: 7114.4653 - val_mean_absolute_error: 33.4417\n",
            "Epoch 133/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6169.6182 - mean_absolute_error: 31.8624 - val_loss: 7127.3525 - val_mean_absolute_error: 34.2956\n",
            "Epoch 134/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6165.1362 - mean_absolute_error: 31.8502 - val_loss: 7117.1553 - val_mean_absolute_error: 33.6713\n",
            "Epoch 135/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6166.2412 - mean_absolute_error: 31.8468 - val_loss: 7112.2524 - val_mean_absolute_error: 33.0852\n",
            "Epoch 136/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6161.8013 - mean_absolute_error: 31.8451 - val_loss: 7120.0977 - val_mean_absolute_error: 33.1935\n",
            "Epoch 137/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6166.1577 - mean_absolute_error: 31.8559 - val_loss: 7084.0151 - val_mean_absolute_error: 33.0187\n",
            "Epoch 138/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6162.1982 - mean_absolute_error: 31.8490 - val_loss: 7089.2334 - val_mean_absolute_error: 32.9276\n",
            "Epoch 139/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6159.9224 - mean_absolute_error: 31.8317 - val_loss: 7093.9102 - val_mean_absolute_error: 33.1268\n",
            "Epoch 140/300\n",
            "141/710 [====>.........................] - ETA: 8s - loss: 6112.0220 - mean_absolute_error: 31.7178"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e87f187ce5c1>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv3D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.activations import relu\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import DepthwiseConv2D\n",
        "\n",
        "\n",
        "# ... Assuming bitboard_dataset and labels are defined ...\n",
        "\n",
        "bitboard_dataset, labels = shuffle(bitboard_dataset, labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bitboard_dataset, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Radial Basis Function activation\n",
        "def rbf(x):\n",
        "    return tf.exp(-x**2)\n",
        "\n",
        "# Input layer\n",
        "input_layer_2d = layers.Input(shape=(15,8, 8))  # for 2D convolutions\n",
        "input_layer_3d = layers.Reshape((15, 8, 8, 1))(input_layer_2d)  # for 3D convolutions\n",
        "\n",
        "# Branch 1: Depthwise Convolution\n",
        "branch1 = DepthwiseConv2D(kernel_size=(1, 1), depth_multiplier=1, activation=relu)(input_layer_2d)\n",
        "branch1 = Conv2D(filters=15, kernel_size=(8, 8), activation=relu)(branch1)\n",
        "branch1 = Flatten()(branch1)  # Flatten branch1\n",
        "# Branch 2: Conv3D\n",
        "branch2 = Conv3D(filters=16, kernel_size=(5, 5, 5), padding='valid', activation=relu)(input_layer_3d)\n",
        "branch2 = Conv3D(filters=8, kernel_size=(3, 3, 3), padding='valid', activation=relu)(branch2)\n",
        "branch2 = Flatten()(branch2)  # Flatten branch2\n",
        "\n",
        "# Branch 3: Conv3 (Only to the 15th channel)\n",
        "branch3_input = tf.gather(input_layer_2d, [13,14], axis=3)  # Extract the 15th channel\n",
        "branch3 = DepthwiseConv2D(kernel_size=(1, 1), depth_multiplier=1, activation=relu)(branch3_input)\n",
        "branch3 = Conv2D(filters=10, kernel_size=(8,8), activation=relu)(branch3)\n",
        "branch3 = Conv2D(filters=2, kernel_size=(1, 1), activation=relu)(branch3)\n",
        "branch3 = Flatten()(branch3)  # Flatten branch3\n",
        "\n",
        "concat = Concatenate()([branch1, branch2, branch3])\n",
        "\n",
        "# Dense layers\n",
        "dense1 = Dense(64, activation='relu')(concat)\n",
        "dense2 = Dense(32, activation='relu')(dense1)\n",
        "dense3 = Dense(16, activation='relu')(dense2)\n",
        "output_layer = Dense(1)(dense3)  # No activation function for regression\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer_2d, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mape'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=1000, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae, mape = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Absolute Percentage Error:\", mape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx_ulGlEr0KK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1696367563331,
          "user_tz": -330,
          "elapsed": 2337,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ecdcaae6-4cdf-4be7-8892-484c84dce14c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-851a245417c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/model1.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/model1.keras'"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/model1.keras')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}