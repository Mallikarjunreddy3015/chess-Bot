{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXu6D-nv_Z3N",
        "outputId": "885ea2b5-922c-4a58-8aae-e534d4337b3b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696593706840,
          "user_tz": -330,
          "elapsed": 23833,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-chess in /usr/local/lib/python3.10/dist-packages (1.999)\n",
            "Requirement already satisfied: chess<2,>=1 in /usr/local/lib/python3.10/dist-packages (from python-chess) (1.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.6.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-chess\n",
        "!pip install psutil\n",
        "!pip install google-cloud-storage\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import chess\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"Total RAM: {memory.total / (1024 ** 3):.2f} GB\")\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "_Kw8L5mmaSlc",
        "outputId": "4372eaa2-9e46-4066-93ae-5bc08fe528a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696590459961,
          "user_tz": -330,
          "elapsed": 8,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 102.18 GB\n",
            "Fri Oct  6 11:07:38 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              10W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/gleaming-modem-400906-3780658b0f47.json\"\n",
        "from google.cloud import storage\n",
        "\n",
        "def download_from_bucket(blob_name, path_to_save_to, bucket_name):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.download_to_filename(path_to_save_to)\n",
        "    print(f\"File {blob_name} downloaded to {path_to_save_to}.\")\n",
        "\n",
        "# Use the function to download your file:\n",
        "download_from_bucket(\"concatenated_array2.npy\", \"/content/concatenated_array2.npy\", \"chess_data_all\")\n",
        "download_from_bucket(\"concatenated_array1.npy\", \"/content/concatenated_array1.npy\", \"chess_data_all\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SV1_hnRi4En",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696586217407,
          "user_tz": -330,
          "elapsed": 611151,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6ef0434d-7491-4ec2-c019-775a047c6087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File concatenated_array2.npy downloaded to /content/concatenated_array2.npy.\n",
            "File concatenated_array1.npy downloaded to /content/concatenated_array1.npy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bnfn9WPEni1p",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696593843269,
          "user_tz": -330,
          "elapsed": 126875,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "bitboard_dataset=np.load(\"/content/concatenated_array1.npy\")\n",
        "labels=np.load(\"/content/concatenated_array2.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv3D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.activations import relu\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import DepthwiseConv2D\n",
        "\n",
        "\n",
        "# ... Assuming bitboard_dataset and labels are defined ...\n",
        "\n",
        "bitboard_dataset, labels = shuffle(bitboard_dataset, labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bitboard_dataset, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Input layer\n",
        "input_layer_2d = layers.Input(shape=(16,8, 8))  # for 2D convolutions\n",
        "input_layer_3d = layers.Reshape((16, 8, 8, 1))(input_layer_2d)  # for 3D convolutions\n"
      ],
      "metadata": {
        "id": "cjyNKNin14dd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696593957689,
          "user_tz": -330,
          "elapsed": 17148,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Branch 1: Depthwise Convolution\n",
        "branch1 = DepthwiseConv2D(kernel_size=(1, 1), depth_multiplier=1, activation=relu)(input_layer_2d)\n",
        "branch4 = Conv2D(filters=5, kernel_size=(8, 8), activation=relu)(branch1)\n",
        "branch1 = Flatten()(branch1)  # Flatten branch1\n",
        "branch4 = Flatten()(branch4)\n",
        "# Branch 2: Conv3D\n",
        "branch2 = Conv3D(filters=16, kernel_size=(5, 5, 5), padding='valid', activation=relu)(input_layer_3d)\n",
        "branch2 = Conv3D(filters=8, kernel_size=(3, 3, 3), padding='valid', activation=relu)(branch2)\n",
        "branch2 = Flatten()(branch2)  # Flatten branch2\n",
        "\n",
        "# Branch 3: Conv3 (Only to the 15th channel)\n",
        "branch3_input = tf.gather(input_layer_2d, [13,14], axis=3)  # Extract the 15th channel\n",
        "branch3 = DepthwiseConv2D(kernel_size=(1, 1), depth_multiplier=1, activation=relu)(branch3_input)\n",
        "branch3 = Conv2D(filters=10, kernel_size=(8,8), activation=relu)(branch3)\n",
        "branch3 = Conv2D(filters=2, kernel_size=(1, 1), activation=relu)(branch3)\n",
        "branch3 = Flatten()(branch3)  # Flatten branch3\n",
        "\n",
        "concat = Concatenate()([branch1, branch2, branch3,branch4])\n",
        "\n",
        "# Dense layers\n",
        "dense1 = Dense(1024, activation='relu')(concat)\n",
        "dense2 = Dense(512, activation='relu')(dense1)\n",
        "dense3 = Dense(128, activation='relu')(dense2)\n",
        "dense4 = Dense(64, activation='relu')(dense3)\n",
        "output_layer = Dense(1)(dense4)  # No activation function for regression\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer_2d, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mape'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=250, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae, mape = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Absolute Percentage Error:\", mape)"
      ],
      "metadata": {
        "id": "tQeo2FuNIIkp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1696601120086,
          "user_tz": -330,
          "elapsed": 7162410,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "167828af-af1c-496f-d77e-a3a8b9ed043d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5707/5707 [==============================] - 56s 7ms/step - loss: 7234.6514 - mae: 33.7384 - mape: 2129335808.0000 - val_loss: 6767.1069 - val_mae: 34.5603 - val_mape: 2744451072.0000\n",
            "Epoch 2/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 6058.1519 - mae: 31.7933 - mape: 2220264960.0000 - val_loss: 6137.2271 - val_mae: 32.7741 - val_mape: 2560189952.0000\n",
            "Epoch 3/200\n",
            "5707/5707 [==============================] - 39s 7ms/step - loss: 5163.1772 - mae: 30.2514 - mape: 2086460544.0000 - val_loss: 5672.9482 - val_mae: 31.1693 - val_mape: 2320307200.0000\n",
            "Epoch 4/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 4434.1006 - mae: 28.8616 - mape: 1952464384.0000 - val_loss: 5415.7832 - val_mae: 30.1318 - val_mape: 2026812672.0000\n",
            "Epoch 5/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 3869.8909 - mae: 27.7487 - mape: 1820376320.0000 - val_loss: 5467.5361 - val_mae: 31.9488 - val_mape: 2381706496.0000\n",
            "Epoch 6/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 3439.5046 - mae: 26.8300 - mape: 1749953536.0000 - val_loss: 5126.1851 - val_mae: 29.2432 - val_mape: 1758115584.0000\n",
            "Epoch 7/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 3112.3577 - mae: 26.0972 - mape: 1689658624.0000 - val_loss: 5042.7427 - val_mae: 29.4315 - val_mape: 2017982336.0000\n",
            "Epoch 8/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 2848.8621 - mae: 25.4686 - mape: 1655871488.0000 - val_loss: 5001.6880 - val_mae: 28.6420 - val_mape: 1759522560.0000\n",
            "Epoch 9/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 2621.3320 - mae: 24.8862 - mape: 1609660928.0000 - val_loss: 4965.0044 - val_mae: 28.5504 - val_mape: 1798435328.0000\n",
            "Epoch 10/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 2427.3276 - mae: 24.3605 - mape: 1565969024.0000 - val_loss: 4919.0156 - val_mae: 28.2905 - val_mape: 1873783040.0000\n",
            "Epoch 11/200\n",
            "5707/5707 [==============================] - 38s 7ms/step - loss: 2273.3711 - mae: 23.9571 - mape: 1529604992.0000 - val_loss: 4879.8501 - val_mae: 27.9022 - val_mape: 1694983040.0000\n",
            "Epoch 12/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 2145.4478 - mae: 23.5589 - mape: 1503875840.0000 - val_loss: 4933.0654 - val_mae: 28.2072 - val_mape: 1794251776.0000\n",
            "Epoch 13/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 2028.6487 - mae: 23.1864 - mape: 1491237120.0000 - val_loss: 4862.2969 - val_mae: 27.5726 - val_mape: 1588387072.0000\n",
            "Epoch 14/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1926.0356 - mae: 22.8265 - mape: 1461186688.0000 - val_loss: 4777.0894 - val_mae: 27.5636 - val_mape: 1604762880.0000\n",
            "Epoch 15/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1828.2838 - mae: 22.4879 - mape: 1452516352.0000 - val_loss: 4795.8867 - val_mae: 27.7142 - val_mape: 1745602304.0000\n",
            "Epoch 16/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1750.3041 - mae: 22.1609 - mape: 1421595136.0000 - val_loss: 4752.9370 - val_mae: 27.2878 - val_mape: 1671034112.0000\n",
            "Epoch 17/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1661.6833 - mae: 21.8161 - mape: 1382876800.0000 - val_loss: 4788.8198 - val_mae: 27.9219 - val_mape: 1964986624.0000\n",
            "Epoch 18/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1588.3721 - mae: 21.5437 - mape: 1366064768.0000 - val_loss: 4772.6714 - val_mae: 27.5233 - val_mape: 1846260480.0000\n",
            "Epoch 19/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1528.4346 - mae: 21.2502 - mape: 1353243136.0000 - val_loss: 4664.7153 - val_mae: 27.1358 - val_mape: 1627201408.0000\n",
            "Epoch 20/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1464.1553 - mae: 20.9833 - mape: 1334726912.0000 - val_loss: 4738.1973 - val_mae: 26.9429 - val_mape: 1655408128.0000\n",
            "Epoch 21/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1407.1007 - mae: 20.7208 - mape: 1315446656.0000 - val_loss: 4653.5708 - val_mae: 26.6868 - val_mape: 1528519040.0000\n",
            "Epoch 22/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1359.3585 - mae: 20.4736 - mape: 1299219456.0000 - val_loss: 4501.9922 - val_mae: 26.3113 - val_mape: 1488023552.0000\n",
            "Epoch 23/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1305.4094 - mae: 20.2063 - mape: 1285278848.0000 - val_loss: 4685.3408 - val_mae: 26.7618 - val_mape: 1609659392.0000\n",
            "Epoch 24/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1259.0574 - mae: 19.9648 - mape: 1270964352.0000 - val_loss: 4632.9375 - val_mae: 26.7031 - val_mape: 1549759616.0000\n",
            "Epoch 25/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1225.4492 - mae: 19.7525 - mape: 1245170688.0000 - val_loss: 4608.9028 - val_mae: 26.3464 - val_mape: 1533005440.0000\n",
            "Epoch 26/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1193.8884 - mae: 19.5568 - mape: 1244782848.0000 - val_loss: 4642.2222 - val_mae: 26.3529 - val_mape: 1505638400.0000\n",
            "Epoch 27/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1150.3094 - mae: 19.3309 - mape: 1226017024.0000 - val_loss: 4480.7490 - val_mae: 25.9023 - val_mape: 1484192896.0000\n",
            "Epoch 28/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1125.5886 - mae: 19.1577 - mape: 1221311104.0000 - val_loss: 4506.7686 - val_mae: 26.1892 - val_mape: 1608953216.0000\n",
            "Epoch 29/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1098.6924 - mae: 18.9546 - mape: 1198084992.0000 - val_loss: 4538.5337 - val_mae: 26.2351 - val_mape: 1634096896.0000\n",
            "Epoch 30/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1058.6217 - mae: 18.7620 - mape: 1187884928.0000 - val_loss: 4477.3608 - val_mae: 25.7676 - val_mape: 1491154304.0000\n",
            "Epoch 31/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 1037.2594 - mae: 18.6136 - mape: 1180287744.0000 - val_loss: 4610.7720 - val_mae: 26.0627 - val_mape: 1601722624.0000\n",
            "Epoch 32/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 1020.4661 - mae: 18.4740 - mape: 1169921152.0000 - val_loss: 4655.9883 - val_mae: 26.1255 - val_mape: 1611764224.0000\n",
            "Epoch 33/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 984.5255 - mae: 18.2256 - mape: 1145320960.0000 - val_loss: 4409.3315 - val_mae: 25.4104 - val_mape: 1429514112.0000\n",
            "Epoch 34/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 965.2854 - mae: 18.1235 - mape: 1140713472.0000 - val_loss: 4475.6714 - val_mae: 25.8046 - val_mape: 1629038592.0000\n",
            "Epoch 35/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 944.2515 - mae: 17.9760 - mape: 1135681408.0000 - val_loss: 4588.6914 - val_mae: 26.1279 - val_mape: 1680569856.0000\n",
            "Epoch 36/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 925.1849 - mae: 17.8189 - mape: 1126841600.0000 - val_loss: 4366.8457 - val_mae: 25.2386 - val_mape: 1483178368.0000\n",
            "Epoch 37/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 914.0018 - mae: 17.7103 - mape: 1118573568.0000 - val_loss: 4463.1963 - val_mae: 25.4725 - val_mape: 1555353984.0000\n",
            "Epoch 38/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 890.5491 - mae: 17.5554 - mape: 1105267968.0000 - val_loss: 4416.6055 - val_mae: 25.3169 - val_mape: 1455952768.0000\n",
            "Epoch 39/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 872.3080 - mae: 17.4116 - mape: 1092918656.0000 - val_loss: 4414.8408 - val_mae: 25.4181 - val_mape: 1534918784.0000\n",
            "Epoch 40/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 844.0367 - mae: 17.2060 - mape: 1078017920.0000 - val_loss: 4467.0269 - val_mae: 25.6132 - val_mape: 1587756160.0000\n",
            "Epoch 41/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 832.2686 - mae: 17.1300 - mape: 1081980032.0000 - val_loss: 4476.0317 - val_mae: 25.3714 - val_mape: 1545881088.0000\n",
            "Epoch 42/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 830.7194 - mae: 17.0497 - mape: 1076974464.0000 - val_loss: 4424.2744 - val_mae: 25.3666 - val_mape: 1590553088.0000\n",
            "Epoch 43/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 805.9791 - mae: 16.8892 - mape: 1062622976.0000 - val_loss: 4342.7070 - val_mae: 24.9104 - val_mape: 1443066752.0000\n",
            "Epoch 44/200\n",
            "5707/5707 [==============================] - 38s 7ms/step - loss: 789.8336 - mae: 16.7660 - mape: 1061075392.0000 - val_loss: 4399.4087 - val_mae: 25.4562 - val_mape: 1616091776.0000\n",
            "Epoch 45/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 771.9821 - mae: 16.6377 - mape: 1044183360.0000 - val_loss: 4434.7207 - val_mae: 25.0313 - val_mape: 1456939776.0000\n",
            "Epoch 46/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 770.5580 - mae: 16.5408 - mape: 1042744320.0000 - val_loss: 4435.0449 - val_mae: 25.3730 - val_mape: 1581339136.0000\n",
            "Epoch 47/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 760.1745 - mae: 16.4564 - mape: 1040970560.0000 - val_loss: 4349.8833 - val_mae: 25.3344 - val_mape: 1639882752.0000\n",
            "Epoch 48/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 738.9254 - mae: 16.3188 - mape: 1032018240.0000 - val_loss: 4394.6689 - val_mae: 25.1942 - val_mape: 1432193280.0000\n",
            "Epoch 49/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 723.9064 - mae: 16.2271 - mape: 1024068864.0000 - val_loss: 4465.6108 - val_mae: 24.8999 - val_mape: 1482015232.0000\n",
            "Epoch 50/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 723.6396 - mae: 16.1710 - mape: 1021589760.0000 - val_loss: 4398.5273 - val_mae: 24.7782 - val_mape: 1410442368.0000\n",
            "Epoch 51/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 706.7062 - mae: 16.0340 - mape: 1010112448.0000 - val_loss: 4345.7188 - val_mae: 24.7924 - val_mape: 1484740992.0000\n",
            "Epoch 52/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 689.3147 - mae: 15.9120 - mape: 999364032.0000 - val_loss: 4476.2886 - val_mae: 25.0243 - val_mape: 1553649408.0000\n",
            "Epoch 53/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 696.6323 - mae: 15.9088 - mape: 1000425216.0000 - val_loss: 4575.0962 - val_mae: 25.1676 - val_mape: 1435246208.0000\n",
            "Epoch 54/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 669.3638 - mae: 15.7309 - mape: 983731840.0000 - val_loss: 4458.3018 - val_mae: 24.8806 - val_mape: 1483892224.0000\n",
            "Epoch 55/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 670.4667 - mae: 15.6770 - mape: 986434944.0000 - val_loss: 4297.9033 - val_mae: 24.6319 - val_mape: 1472138752.0000\n",
            "Epoch 56/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 651.1682 - mae: 15.5506 - mape: 977106816.0000 - val_loss: 4484.7129 - val_mae: 25.1362 - val_mape: 1554099200.0000\n",
            "Epoch 57/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 649.0517 - mae: 15.4984 - mape: 973238144.0000 - val_loss: 4386.6108 - val_mae: 24.7865 - val_mape: 1533145984.0000\n",
            "Epoch 58/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 651.1328 - mae: 15.4542 - mape: 971769344.0000 - val_loss: 4415.0112 - val_mae: 24.7626 - val_mape: 1511843328.0000\n",
            "Epoch 59/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 635.6287 - mae: 15.3737 - mape: 970742464.0000 - val_loss: 4545.2705 - val_mae: 25.2306 - val_mape: 1614271104.0000\n",
            "Epoch 60/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 628.9905 - mae: 15.2600 - mape: 961522176.0000 - val_loss: 4429.0903 - val_mae: 24.8486 - val_mape: 1520839424.0000\n",
            "Epoch 61/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 626.7433 - mae: 15.2267 - mape: 960104128.0000 - val_loss: 4425.1680 - val_mae: 24.7327 - val_mape: 1516621568.0000\n",
            "Epoch 62/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 617.9374 - mae: 15.1863 - mape: 957173440.0000 - val_loss: 4472.6265 - val_mae: 24.7575 - val_mape: 1452778112.0000\n",
            "Epoch 63/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 610.3093 - mae: 15.1252 - mape: 951883648.0000 - val_loss: 4326.9155 - val_mae: 24.4240 - val_mape: 1386070784.0000\n",
            "Epoch 64/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 592.0746 - mae: 14.9470 - mape: 942664832.0000 - val_loss: 4392.6987 - val_mae: 24.4759 - val_mape: 1448737792.0000\n",
            "Epoch 65/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 602.6651 - mae: 15.0067 - mape: 945465792.0000 - val_loss: 4405.7319 - val_mae: 24.5246 - val_mape: 1499897472.0000\n",
            "Epoch 66/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 591.9288 - mae: 14.8965 - mape: 938463168.0000 - val_loss: 4318.1919 - val_mae: 24.6322 - val_mape: 1509661184.0000\n",
            "Epoch 67/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 573.7471 - mae: 14.7569 - mape: 927857856.0000 - val_loss: 4432.6465 - val_mae: 24.9324 - val_mape: 1493952256.0000\n",
            "Epoch 68/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 569.5446 - mae: 14.6830 - mape: 918512448.0000 - val_loss: 4361.1895 - val_mae: 24.2940 - val_mape: 1399330432.0000\n",
            "Epoch 69/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 565.8953 - mae: 14.6756 - mape: 922975616.0000 - val_loss: 4420.1792 - val_mae: 24.6729 - val_mape: 1506054144.0000\n",
            "Epoch 70/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 556.8301 - mae: 14.5614 - mape: 916226112.0000 - val_loss: 4391.7749 - val_mae: 24.5292 - val_mape: 1461304960.0000\n",
            "Epoch 71/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 564.0739 - mae: 14.6128 - mape: 914491456.0000 - val_loss: 4415.5674 - val_mae: 24.4524 - val_mape: 1455565952.0000\n",
            "Epoch 72/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 552.3374 - mae: 14.4824 - mape: 908427264.0000 - val_loss: 4435.5703 - val_mae: 24.4842 - val_mape: 1413040384.0000\n",
            "Epoch 73/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 542.0737 - mae: 14.3744 - mape: 901389632.0000 - val_loss: 4346.8223 - val_mae: 24.2766 - val_mape: 1428861312.0000\n",
            "Epoch 74/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 537.6802 - mae: 14.3535 - mape: 901896384.0000 - val_loss: 4325.2349 - val_mae: 24.5938 - val_mape: 1594976256.0000\n",
            "Epoch 75/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 535.3217 - mae: 14.3073 - mape: 900188928.0000 - val_loss: 4397.2720 - val_mae: 24.2627 - val_mape: 1461640448.0000\n",
            "Epoch 76/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 527.1002 - mae: 14.2235 - mape: 896478912.0000 - val_loss: 4447.4966 - val_mae: 24.5830 - val_mape: 1533430784.0000\n",
            "Epoch 77/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 522.1962 - mae: 14.1618 - mape: 890670016.0000 - val_loss: 4372.5586 - val_mae: 24.2244 - val_mape: 1458182656.0000\n",
            "Epoch 78/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 507.4023 - mae: 14.0441 - mape: 881078464.0000 - val_loss: 4380.2490 - val_mae: 24.1708 - val_mape: 1380767616.0000\n",
            "Epoch 79/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 511.5884 - mae: 14.0385 - mape: 876366144.0000 - val_loss: 4436.4888 - val_mae: 24.5568 - val_mape: 1385314816.0000\n",
            "Epoch 80/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 514.0760 - mae: 14.0864 - mape: 886738368.0000 - val_loss: 4368.8901 - val_mae: 24.3114 - val_mape: 1395523328.0000\n",
            "Epoch 81/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 511.7135 - mae: 14.0034 - mape: 875198592.0000 - val_loss: 4429.2808 - val_mae: 24.4619 - val_mape: 1540792576.0000\n",
            "Epoch 82/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 501.6747 - mae: 13.8935 - mape: 867356352.0000 - val_loss: 4358.1118 - val_mae: 24.3993 - val_mape: 1449111808.0000\n",
            "Epoch 83/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 500.2668 - mae: 13.8979 - mape: 872295488.0000 - val_loss: 4478.0356 - val_mae: 24.6455 - val_mape: 1582759680.0000\n",
            "Epoch 84/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 492.7113 - mae: 13.8154 - mape: 866137792.0000 - val_loss: 4394.4102 - val_mae: 24.3951 - val_mape: 1461625856.0000\n",
            "Epoch 85/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 495.8575 - mae: 13.8346 - mape: 871927616.0000 - val_loss: 4451.0859 - val_mae: 24.3682 - val_mape: 1386576640.0000\n",
            "Epoch 86/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 492.0937 - mae: 13.7893 - mape: 867502656.0000 - val_loss: 4445.8950 - val_mae: 24.3295 - val_mape: 1457663488.0000\n",
            "Epoch 87/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 477.3441 - mae: 13.6599 - mape: 853173632.0000 - val_loss: 4383.2271 - val_mae: 24.2087 - val_mape: 1450492416.0000\n",
            "Epoch 88/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 464.8429 - mae: 13.5378 - mape: 843648384.0000 - val_loss: 4344.5503 - val_mae: 24.1060 - val_mape: 1362296064.0000\n",
            "Epoch 89/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 474.2736 - mae: 13.6154 - mape: 848998528.0000 - val_loss: 4397.2109 - val_mae: 24.2706 - val_mape: 1465626240.0000\n",
            "Epoch 90/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 470.3029 - mae: 13.5316 - mape: 843708672.0000 - val_loss: 4521.9023 - val_mae: 24.4825 - val_mape: 1517283456.0000\n",
            "Epoch 91/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 470.7204 - mae: 13.5560 - mape: 847299200.0000 - val_loss: 4380.1094 - val_mae: 24.2426 - val_mape: 1533537152.0000\n",
            "Epoch 92/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 469.3338 - mae: 13.4850 - mape: 842144768.0000 - val_loss: 4445.8965 - val_mae: 24.5559 - val_mape: 1509371136.0000\n",
            "Epoch 93/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 461.7658 - mae: 13.4442 - mape: 835897536.0000 - val_loss: 4477.6089 - val_mae: 24.4586 - val_mape: 1583754880.0000\n",
            "Epoch 94/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 461.5844 - mae: 13.4279 - mape: 840385984.0000 - val_loss: 4355.2656 - val_mae: 23.9517 - val_mape: 1336671616.0000\n",
            "Epoch 95/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 464.3870 - mae: 13.4273 - mape: 830679424.0000 - val_loss: 4394.7959 - val_mae: 24.5154 - val_mape: 1602371072.0000\n",
            "Epoch 96/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 456.0627 - mae: 13.3686 - mape: 833980608.0000 - val_loss: 4411.8550 - val_mae: 24.0424 - val_mape: 1376429696.0000\n",
            "Epoch 97/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 451.5430 - mae: 13.3150 - mape: 829144640.0000 - val_loss: 4411.5049 - val_mae: 24.2348 - val_mape: 1493881344.0000\n",
            "Epoch 98/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 457.7166 - mae: 13.3175 - mape: 832178240.0000 - val_loss: 4420.5586 - val_mae: 24.4952 - val_mape: 1582018048.0000\n",
            "Epoch 99/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 443.3017 - mae: 13.2252 - mape: 827063104.0000 - val_loss: 4411.9326 - val_mae: 24.3232 - val_mape: 1420207232.0000\n",
            "Epoch 100/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 431.8230 - mae: 13.1088 - mape: 817748224.0000 - val_loss: 4411.9409 - val_mae: 24.1557 - val_mape: 1436499072.0000\n",
            "Epoch 101/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 436.6729 - mae: 13.1289 - mape: 819907968.0000 - val_loss: 4416.1035 - val_mae: 24.0758 - val_mape: 1388743680.0000\n",
            "Epoch 102/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 437.0508 - mae: 13.1101 - mape: 813884992.0000 - val_loss: 4415.7900 - val_mae: 24.1366 - val_mape: 1510580096.0000\n",
            "Epoch 103/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 449.1907 - mae: 13.1958 - mape: 822480768.0000 - val_loss: 4287.7656 - val_mae: 23.7213 - val_mape: 1369523456.0000\n",
            "Epoch 104/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 443.9138 - mae: 13.1256 - mape: 814227712.0000 - val_loss: 4484.5010 - val_mae: 24.2998 - val_mape: 1518502656.0000\n",
            "Epoch 105/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 418.0188 - mae: 12.9565 - mape: 805160064.0000 - val_loss: 4474.0586 - val_mae: 24.2592 - val_mape: 1508813952.0000\n",
            "Epoch 106/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 426.3694 - mae: 12.9943 - mape: 805334848.0000 - val_loss: 4384.9019 - val_mae: 24.1182 - val_mape: 1438521728.0000\n",
            "Epoch 107/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 416.7809 - mae: 12.9123 - mape: 802273344.0000 - val_loss: 4387.9272 - val_mae: 24.2810 - val_mape: 1437445888.0000\n",
            "Epoch 108/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 424.3781 - mae: 12.9285 - mape: 800224640.0000 - val_loss: 4406.6523 - val_mae: 24.2389 - val_mape: 1533311616.0000\n",
            "Epoch 109/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 410.4472 - mae: 12.8110 - mape: 795328256.0000 - val_loss: 4490.7119 - val_mae: 24.5890 - val_mape: 1448371584.0000\n",
            "Epoch 110/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 417.2484 - mae: 12.8450 - mape: 797021888.0000 - val_loss: 4557.2876 - val_mae: 24.4717 - val_mape: 1386540928.0000\n",
            "Epoch 111/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 416.7707 - mae: 12.8791 - mape: 804296576.0000 - val_loss: 4406.9526 - val_mae: 23.9892 - val_mape: 1489872768.0000\n",
            "Epoch 112/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 403.1259 - mae: 12.7131 - mape: 790484864.0000 - val_loss: 4531.9316 - val_mae: 24.5971 - val_mape: 1583253504.0000\n",
            "Epoch 113/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 416.1465 - mae: 12.7944 - mape: 796009664.0000 - val_loss: 4437.3345 - val_mae: 24.4986 - val_mape: 1596865024.0000\n",
            "Epoch 114/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 410.8321 - mae: 12.7565 - mape: 791244288.0000 - val_loss: 4540.1162 - val_mae: 24.1764 - val_mape: 1477145856.0000\n",
            "Epoch 115/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 404.6332 - mae: 12.7499 - mape: 792877568.0000 - val_loss: 4535.0820 - val_mae: 24.4567 - val_mape: 1560263040.0000\n",
            "Epoch 116/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 423.8523 - mae: 12.8151 - mape: 791930496.0000 - val_loss: 4485.8418 - val_mae: 24.0665 - val_mape: 1381444864.0000\n",
            "Epoch 117/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 401.4102 - mae: 12.6074 - mape: 779747264.0000 - val_loss: 4421.2822 - val_mae: 24.1150 - val_mape: 1499972096.0000\n",
            "Epoch 118/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 396.4511 - mae: 12.6016 - mape: 782333888.0000 - val_loss: 4463.2114 - val_mae: 23.9716 - val_mape: 1398304640.0000\n",
            "Epoch 119/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 400.5316 - mae: 12.6378 - mape: 782512832.0000 - val_loss: 4445.2896 - val_mae: 23.9064 - val_mape: 1405904000.0000\n",
            "Epoch 120/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 391.0948 - mae: 12.5345 - mape: 776407168.0000 - val_loss: 4422.2778 - val_mae: 23.9846 - val_mape: 1512750208.0000\n",
            "Epoch 121/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 390.5216 - mae: 12.4999 - mape: 768622976.0000 - val_loss: 4448.5786 - val_mae: 23.9335 - val_mape: 1367426048.0000\n",
            "Epoch 122/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 377.1807 - mae: 12.3702 - mape: 770017856.0000 - val_loss: 4507.2563 - val_mae: 24.4199 - val_mape: 1538744448.0000\n",
            "Epoch 123/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 379.2782 - mae: 12.3958 - mape: 766633408.0000 - val_loss: 4513.4707 - val_mae: 24.6679 - val_mape: 1597325696.0000\n",
            "Epoch 124/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 380.4834 - mae: 12.4112 - mape: 769338624.0000 - val_loss: 4434.8086 - val_mae: 23.8960 - val_mape: 1410119552.0000\n",
            "Epoch 125/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 385.2098 - mae: 12.4650 - mape: 770901696.0000 - val_loss: 4399.5557 - val_mae: 24.0448 - val_mape: 1445091584.0000\n",
            "Epoch 126/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 385.3594 - mae: 12.3965 - mape: 767319936.0000 - val_loss: 4451.7329 - val_mae: 23.8795 - val_mape: 1396227200.0000\n",
            "Epoch 127/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 384.4175 - mae: 12.4091 - mape: 763206016.0000 - val_loss: 4416.3047 - val_mae: 23.9065 - val_mape: 1367559040.0000\n",
            "Epoch 128/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 369.7532 - mae: 12.2809 - mape: 759968384.0000 - val_loss: 4479.3418 - val_mae: 23.9023 - val_mape: 1404247424.0000\n",
            "Epoch 129/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 369.9103 - mae: 12.2781 - mape: 757747392.0000 - val_loss: 4453.0171 - val_mae: 23.9427 - val_mape: 1434222976.0000\n",
            "Epoch 130/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 374.9922 - mae: 12.2908 - mape: 761757120.0000 - val_loss: 4424.4878 - val_mae: 23.8400 - val_mape: 1435789824.0000\n",
            "Epoch 131/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 373.6008 - mae: 12.3138 - mape: 767415680.0000 - val_loss: 4577.8213 - val_mae: 24.2183 - val_mape: 1469546496.0000\n",
            "Epoch 132/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 388.1756 - mae: 12.3493 - mape: 761561472.0000 - val_loss: 4564.3027 - val_mae: 24.2270 - val_mape: 1517503232.0000\n",
            "Epoch 133/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 378.4208 - mae: 12.3029 - mape: 762800448.0000 - val_loss: 4424.3809 - val_mae: 23.8360 - val_mape: 1402408576.0000\n",
            "Epoch 134/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 357.7322 - mae: 12.1026 - mape: 752238464.0000 - val_loss: 4614.9565 - val_mae: 24.5477 - val_mape: 1530034816.0000\n",
            "Epoch 135/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 358.0143 - mae: 12.0931 - mape: 746150720.0000 - val_loss: 4437.4883 - val_mae: 23.9036 - val_mape: 1468666624.0000\n",
            "Epoch 136/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 360.0054 - mae: 12.1178 - mape: 747658880.0000 - val_loss: 4420.6606 - val_mae: 23.9461 - val_mape: 1440706304.0000\n",
            "Epoch 137/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 372.3170 - mae: 12.1685 - mape: 752613952.0000 - val_loss: 4512.2236 - val_mae: 24.0553 - val_mape: 1484860928.0000\n",
            "Epoch 138/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 365.0532 - mae: 12.0870 - mape: 745882432.0000 - val_loss: 4569.6899 - val_mae: 24.5632 - val_mape: 1582577920.0000\n",
            "Epoch 139/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 354.4512 - mae: 12.0425 - mape: 735822528.0000 - val_loss: 4429.5703 - val_mae: 23.9504 - val_mape: 1481384704.0000\n",
            "Epoch 140/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 341.9506 - mae: 11.9160 - mape: 734423104.0000 - val_loss: 4456.1411 - val_mae: 24.0920 - val_mape: 1475215104.0000\n",
            "Epoch 141/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 344.3561 - mae: 11.8939 - mape: 734309952.0000 - val_loss: 4457.7041 - val_mae: 23.6766 - val_mape: 1372662016.0000\n",
            "Epoch 142/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 348.6828 - mae: 11.9314 - mape: 733934912.0000 - val_loss: 4485.7256 - val_mae: 23.8276 - val_mape: 1323316736.0000\n",
            "Epoch 143/200\n",
            "5707/5707 [==============================] - 38s 7ms/step - loss: 346.4750 - mae: 11.9097 - mape: 732526464.0000 - val_loss: 4389.5024 - val_mae: 23.6760 - val_mape: 1415849728.0000\n",
            "Epoch 144/200\n",
            "5707/5707 [==============================] - 38s 7ms/step - loss: 338.5494 - mae: 11.8258 - mape: 737091968.0000 - val_loss: 4411.0210 - val_mae: 23.7248 - val_mape: 1358234112.0000\n",
            "Epoch 145/200\n",
            "5707/5707 [==============================] - 39s 7ms/step - loss: 340.7289 - mae: 11.8375 - mape: 729673728.0000 - val_loss: 4459.2021 - val_mae: 24.1070 - val_mape: 1520142208.0000\n",
            "Epoch 146/200\n",
            "5707/5707 [==============================] - 38s 7ms/step - loss: 345.9655 - mae: 11.9092 - mape: 737517824.0000 - val_loss: 4402.7676 - val_mae: 23.8185 - val_mape: 1381619584.0000\n",
            "Epoch 147/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 347.5026 - mae: 11.8833 - mape: 735953152.0000 - val_loss: 4507.7910 - val_mae: 24.2640 - val_mape: 1576796032.0000\n",
            "Epoch 148/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 336.9387 - mae: 11.7995 - mape: 724091712.0000 - val_loss: 4440.4521 - val_mae: 23.8693 - val_mape: 1450324096.0000\n",
            "Epoch 149/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 342.5862 - mae: 11.7909 - mape: 724414272.0000 - val_loss: 4451.5049 - val_mae: 23.7086 - val_mape: 1393729024.0000\n",
            "Epoch 150/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 337.1056 - mae: 11.7517 - mape: 721797952.0000 - val_loss: 4483.5098 - val_mae: 23.9374 - val_mape: 1482848768.0000\n",
            "Epoch 151/200\n",
            "5707/5707 [==============================] - 39s 7ms/step - loss: 336.9875 - mae: 11.7721 - mape: 725737344.0000 - val_loss: 4437.1973 - val_mae: 23.8730 - val_mape: 1405721344.0000\n",
            "Epoch 152/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 339.2752 - mae: 11.7733 - mape: 717090560.0000 - val_loss: 4474.2920 - val_mae: 23.8126 - val_mape: 1465005440.0000\n",
            "Epoch 153/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 341.0987 - mae: 11.7606 - mape: 721044736.0000 - val_loss: 4487.4448 - val_mae: 23.8012 - val_mape: 1417536256.0000\n",
            "Epoch 154/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 325.3715 - mae: 11.6272 - mape: 717029952.0000 - val_loss: 4517.6665 - val_mae: 23.9921 - val_mape: 1463753856.0000\n",
            "Epoch 155/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 325.3764 - mae: 11.6342 - mape: 713219712.0000 - val_loss: 4530.1943 - val_mae: 23.9514 - val_mape: 1393378560.0000\n",
            "Epoch 156/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 336.3129 - mae: 11.7035 - mape: 718577984.0000 - val_loss: 4440.0298 - val_mae: 23.8874 - val_mape: 1454227200.0000\n",
            "Epoch 157/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 341.5434 - mae: 11.7842 - mape: 722975872.0000 - val_loss: 4483.5752 - val_mae: 23.9847 - val_mape: 1440182528.0000\n",
            "Epoch 158/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 335.6943 - mae: 11.7037 - mape: 719233856.0000 - val_loss: 4511.9541 - val_mae: 23.9490 - val_mape: 1477211904.0000\n",
            "Epoch 159/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 332.8932 - mae: 11.6411 - mape: 716719104.0000 - val_loss: 4462.7197 - val_mae: 23.8371 - val_mape: 1458402688.0000\n",
            "Epoch 160/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 320.2450 - mae: 11.5274 - mape: 705838912.0000 - val_loss: 4455.6372 - val_mae: 23.6642 - val_mape: 1387748096.0000\n",
            "Epoch 161/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 338.2309 - mae: 11.6908 - mape: 719135296.0000 - val_loss: 4558.0078 - val_mae: 24.2068 - val_mape: 1495652608.0000\n",
            "Epoch 162/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 321.2100 - mae: 11.5467 - mape: 711820672.0000 - val_loss: 4475.3027 - val_mae: 24.0455 - val_mape: 1434411520.0000\n",
            "Epoch 163/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 325.7437 - mae: 11.6088 - mape: 711403456.0000 - val_loss: 4536.9531 - val_mae: 23.8100 - val_mape: 1445348608.0000\n",
            "Epoch 164/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 323.3922 - mae: 11.5264 - mape: 708780352.0000 - val_loss: 4629.4019 - val_mae: 24.3925 - val_mape: 1543937536.0000\n",
            "Epoch 165/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 318.9494 - mae: 11.5334 - mape: 708598016.0000 - val_loss: 4474.7217 - val_mae: 24.1203 - val_mape: 1433237888.0000\n",
            "Epoch 166/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 316.2886 - mae: 11.4788 - mape: 707745088.0000 - val_loss: 4446.7183 - val_mae: 23.8397 - val_mape: 1392508672.0000\n",
            "Epoch 167/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 313.0749 - mae: 11.4073 - mape: 701989056.0000 - val_loss: 4563.7700 - val_mae: 24.0742 - val_mape: 1473787008.0000\n",
            "Epoch 168/200\n",
            "5707/5707 [==============================] - 37s 7ms/step - loss: 321.3376 - mae: 11.4890 - mape: 708184320.0000 - val_loss: 4471.3735 - val_mae: 23.9744 - val_mape: 1348835328.0000\n",
            "Epoch 169/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 319.5353 - mae: 11.4626 - mape: 707437568.0000 - val_loss: 4451.9360 - val_mae: 23.6186 - val_mape: 1370203520.0000\n",
            "Epoch 170/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 317.8373 - mae: 11.4296 - mape: 697400064.0000 - val_loss: 4554.1968 - val_mae: 24.0830 - val_mape: 1477067392.0000\n",
            "Epoch 171/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 315.4326 - mae: 11.3876 - mape: 694939008.0000 - val_loss: 4445.3325 - val_mae: 23.5866 - val_mape: 1324908416.0000\n",
            "Epoch 172/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 304.4065 - mae: 11.3046 - mape: 693543808.0000 - val_loss: 4443.6665 - val_mae: 23.8710 - val_mape: 1441793280.0000\n",
            "Epoch 173/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 300.6457 - mae: 11.2315 - mape: 684526720.0000 - val_loss: 4444.6118 - val_mae: 23.7975 - val_mape: 1422457472.0000\n",
            "Epoch 174/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 304.7370 - mae: 11.3016 - mape: 690980224.0000 - val_loss: 4467.4741 - val_mae: 23.9724 - val_mape: 1500089472.0000\n",
            "Epoch 175/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 297.0118 - mae: 11.2069 - mape: 687231360.0000 - val_loss: 4547.0186 - val_mae: 23.8920 - val_mape: 1321237504.0000\n",
            "Epoch 176/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 302.1162 - mae: 11.2573 - mape: 685654080.0000 - val_loss: 4511.9346 - val_mae: 24.1292 - val_mape: 1504865280.0000\n",
            "Epoch 177/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 293.8809 - mae: 11.1192 - mape: 680336768.0000 - val_loss: 4575.2129 - val_mae: 24.5559 - val_mape: 1605601664.0000\n",
            "Epoch 178/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 294.9294 - mae: 11.1328 - mape: 677918272.0000 - val_loss: 4458.3789 - val_mae: 23.7332 - val_mape: 1400676352.0000\n",
            "Epoch 179/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 297.1650 - mae: 11.1602 - mape: 682559616.0000 - val_loss: 4451.7642 - val_mae: 23.7961 - val_mape: 1471113984.0000\n",
            "Epoch 180/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 298.3773 - mae: 11.1466 - mape: 682185280.0000 - val_loss: 4486.2544 - val_mae: 23.6653 - val_mape: 1370373376.0000\n",
            "Epoch 181/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 283.3185 - mae: 11.0003 - mape: 669325632.0000 - val_loss: 4490.3560 - val_mae: 23.9747 - val_mape: 1503755264.0000\n",
            "Epoch 182/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 289.2304 - mae: 11.0617 - mape: 669726912.0000 - val_loss: 4586.4106 - val_mae: 24.2528 - val_mape: 1484764672.0000\n",
            "Epoch 183/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 310.6576 - mae: 11.2922 - mape: 686916032.0000 - val_loss: 4484.1162 - val_mae: 24.0059 - val_mape: 1519317632.0000\n",
            "Epoch 184/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 302.6243 - mae: 11.1792 - mape: 684249984.0000 - val_loss: 4500.8872 - val_mae: 23.9212 - val_mape: 1411807360.0000\n",
            "Epoch 185/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 301.3054 - mae: 11.1460 - mape: 678223744.0000 - val_loss: 4455.1494 - val_mae: 23.7955 - val_mape: 1405271296.0000\n",
            "Epoch 186/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 306.4075 - mae: 11.2163 - mape: 689557056.0000 - val_loss: 4535.2729 - val_mae: 24.0664 - val_mape: 1478394496.0000\n",
            "Epoch 187/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 299.8810 - mae: 11.1327 - mape: 682562048.0000 - val_loss: 4578.2520 - val_mae: 24.0751 - val_mape: 1421308928.0000\n",
            "Epoch 188/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 300.2332 - mae: 11.1333 - mape: 680740608.0000 - val_loss: 4518.6104 - val_mae: 24.0096 - val_mape: 1397625216.0000\n",
            "Epoch 189/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 298.0528 - mae: 11.1206 - mape: 673360320.0000 - val_loss: 4420.9160 - val_mae: 23.6737 - val_mape: 1371863168.0000\n",
            "Epoch 190/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 297.8444 - mae: 11.1288 - mape: 675477696.0000 - val_loss: 4481.0591 - val_mae: 23.8910 - val_mape: 1433928448.0000\n",
            "Epoch 191/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 306.8181 - mae: 11.2023 - mape: 681087232.0000 - val_loss: 4613.6895 - val_mae: 24.3343 - val_mape: 1507432192.0000\n",
            "Epoch 192/200\n",
            "5707/5707 [==============================] - 37s 6ms/step - loss: 294.2182 - mae: 11.0476 - mape: 672035072.0000 - val_loss: 4544.0322 - val_mae: 23.8905 - val_mape: 1401561088.0000\n",
            "Epoch 193/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 296.9159 - mae: 11.1061 - mape: 679238208.0000 - val_loss: 4505.5625 - val_mae: 23.7624 - val_mape: 1454623872.0000\n",
            "Epoch 194/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 293.6943 - mae: 11.0565 - mape: 674810752.0000 - val_loss: 4408.9287 - val_mae: 23.6547 - val_mape: 1478112768.0000\n",
            "Epoch 195/200\n",
            "5707/5707 [==============================] - 36s 6ms/step - loss: 297.4064 - mae: 11.0621 - mape: 674304896.0000 - val_loss: 4466.8550 - val_mae: 23.9034 - val_mape: 1469791360.0000\n",
            "Epoch 196/200\n",
            "3220/5707 [===============>..............] - ETA: 15s - loss: 280.6449 - mae: 10.8893 - mape: 661449088.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d6d96d19c458>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}