{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXu6D-nv_Z3N",
        "outputId": "1d09613a-ac50-4599-ec47-d3246a6d3d01",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360060337,
          "user_tz": -330,
          "elapsed": 17388,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Obtaining dependency information for chess<2,>=1 from https://files.pythonhosted.org/packages/d6/d8/15cfcb738d2518daf04d34b23419bd359cbd8e09da50778ebac521774fc8/chess-1.10.0-py3-none-any.whl.metadata\n",
            "  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess, python-chess\n",
            "Successfully installed chess-1.10.0 python-chess-1.999\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install python-chess\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import chess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FeCoY3TqrFPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1886bcc4-d531-45f0-ed95-133186c29a7d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360160628,
          "user_tz": -330,
          "elapsed": 20090,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading chessfendataset.zip to /content\n",
            "100% 144M/144M [00:06<00:00, 29.1MB/s]\n",
            "100% 144M/144M [00:06<00:00, 22.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "!pip install kaggle\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "!kaggle datasets download -d mallikarjunreddy3015/chessfendataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Get system memory information\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"Total RAM: {memory.total / (1024 ** 3):.2f} GB\")\n",
        "print(f\"Used RAM: {memory.used / (1024 ** 3):.2f} GB\")\n",
        "print(f\"Free RAM: {memory.free / (1024 ** 3):.2f} GB\")\n"
      ],
      "metadata": {
        "id": "_Kw8L5mmaSlc",
        "outputId": "377d6ae1-92a5-43ac-a944-696b8a39fa87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360162929,
          "user_tz": -330,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 58.87 GB\n",
            "Used RAM: 1.48 GB\n",
            "Free RAM: 55.58 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'your-dataset.zip' with the actual zip file name\n",
        "with zipfile.ZipFile('/content/chessfendataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/chessfendataset')\n"
      ],
      "metadata": {
        "id": "IXadynQ0WgkB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360173537,
          "user_tz": -330,
          "elapsed": 5773,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bPvv15KtoS7k",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360223441,
          "user_tz": -330,
          "elapsed": 16451,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv('/content/chessfendataset/chessData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkzx33u0Snt_",
        "outputId": "dd1d17f2-4e9e-4ef4-95b2-d969d9214aa1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360223441,
          "user_tz": -330,
          "elapsed": 31,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  3 19:10:19 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1yQdZKrXsNU3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360234234,
          "user_tz": -330,
          "elapsed": 968,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "dataframe.head()\n",
        "d=dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XQdVPluX9Ngk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360275833,
          "user_tz": -330,
          "elapsed": 32738,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "d.shape\n",
        "d1=d.iloc[0:10000000 ,:]\n",
        "d1.shape\n",
        "d1 = d1[~d1['Evaluation'].str.contains('\\ufeff|#', na=False)]\n",
        "d1['Evaluation'] = pd.to_numeric(d1['Evaluation'].str.replace('[^\\d.-]', '', regex=True), errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Evt8Knj7KO-_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696360275834,
          "user_tz": -330,
          "elapsed": 29,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "d1['Scaled_Evaluation'] = 1000 * (2 * (d1['Evaluation'] +7000) / (14000) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mBXGrD1GbmOd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696364447555,
          "user_tz": -330,
          "elapsed": 4111750,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def generate_bitboard_with_moves(fen):\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    bitboards = np.zeros((15, 8, 8), dtype=np.int8)\n",
        "\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "\n",
        "        if piece is not None:\n",
        "            piece_type = piece.piece_type - 1 if piece.color == chess.WHITE else piece.piece_type + 5\n",
        "            if(piece_type<6):\n",
        "               bitboards[piece_type, square // 8, square % 8] = (piece_type +1)\n",
        "            else:\n",
        "                 bitboards[piece_type, square // 8, square % 8] = -(piece_type -5)\n",
        "\n",
        "    legal_moves = [move.from_square for move in board.legal_moves]\n",
        "\n",
        "    for from_square in legal_moves:\n",
        "\n",
        "        bitboards[12, from_square // 8, from_square % 8] = 1 if board.turn == chess.WHITE else -1\n",
        "\n",
        "    # Add information about en passant square\n",
        "    if board.has_legal_en_passant():\n",
        "        ep_square = board.ep_square\n",
        "        bitboards[13, ep_square // 8, ep_square % 8] = 1 if board.turn == chess.WHITE else -1\n",
        "\n",
        "    # Add bitboards for all black and white pieces\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece is not None:\n",
        "            piece_type = piece.piece_type - 1 if piece.color == chess.WHITE else -(piece.piece_type + 1)\n",
        "            bitboards[14, square // 8, square % 8] = piece_type + 1\n",
        "\n",
        "\n",
        "    return bitboards\n",
        "\n",
        "bitboard_dataset = [generate_bitboard_with_moves(fen) for fen in d1['FEN']]\n",
        "# print(generate_bitboard_with_moves(d1[\"FEN\"][1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqTgX7ZxK9pL"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import chess\n",
        "# import chess.svg\n",
        "# from IPython.display import display, SVG\n",
        "\n",
        "# # Assuming d1 is your DataFrame\n",
        "# for index, row in d1.iterrows():\n",
        "#     if row['Scaled_Evaluation'] < -5000:\n",
        "#         fen = row['FEN']\n",
        "#         board = chess.Board(fen)\n",
        "#         print(f\"FEN: {fen}\")\n",
        "#         print(f\"Scaled_Evaluation: {row['Scaled_Evaluation']}\")\n",
        "#         print(\"Chessboard:\")\n",
        "#         display(SVG(chess.svg.board(board=board, size=500)))\n",
        "#         print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trBRMhJG-GBE"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import chess\n",
        "\n",
        "# def generate_bitboard_with_moves(fen):\n",
        "#     board = chess.Board(fen)\n",
        "\n",
        "#     # Initialize empty 3D matrix of bitboards for each piece type\n",
        "#     bitboards = np.zeros((12, 8, 8), dtype=np.int8)\n",
        "\n",
        "#     # Iterate over all squares on the board\n",
        "#     for square in chess.SQUARES:\n",
        "#         piece = board.piece_at(square)\n",
        "\n",
        "#         if piece is not None:\n",
        "#             # Determine piece type\n",
        "#             piece_type = piece.piece_type - 1 if piece.color == chess.WHITE else piece.piece_type + 5\n",
        "\n",
        "#             # Mark the piece's position on the bitboard\n",
        "#             bitboards[piece_type, square // 8, square % 8] = (piece_type + 1)*11\n",
        "\n",
        "#             # Generate legal moves for the piece at the square\n",
        "#             legal_moves = [move.to_square for move in board.legal_moves if move.from_square == square]\n",
        "\n",
        "#             # Mark legal moves on the bitboard\n",
        "#             for move_square in legal_moves:\n",
        "#                 bitboards[piece_type, move_square // 8, move_square % 8] = piece_type + 1\n",
        "\n",
        "#     return bitboards\n",
        "# bitboard_dataset = [generate_bitboard_with_moves(fen) for fen in d1['FEN']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFSsXYpsWrou",
        "outputId": "75cc03e3-66c8-4655-a139-be19a9483641",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696364461943,
          "user_tz": -330,
          "elapsed": 12865,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0  0  0  0  0  0  0  0]\n",
            "  [ 1  1  0  0  0  0  1  1]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  1  0  0]\n",
            "  [ 0  0  0  0  1  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  2  0  0  0]\n",
            "  [ 0  0  0  0  0  2  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  3  0  0  0  0]\n",
            "  [ 0  0  0  3  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 4  0  0  0  0  0  0  4]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  5  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  6  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0 -1  0  0  0  0]\n",
            "  [ 0  0  0  0 -1 -1  0  0]\n",
            "  [-1 -1  0  0  0  0 -1 -1]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0 -2  0  0  0  0  0]\n",
            "  [ 0  0  0 -2  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0 -3  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0 -3  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [-4  0  0  0  0  0  0 -4]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0 -5  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0 -6  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0 -1  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0 -1 -1  0  0 -1  0  0]\n",
            "  [-1  0  0 -1  0  0 -1 -1]\n",
            "  [-1  0  0  0 -1  0  0 -1]]\n",
            "\n",
            " [[ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0  0  0]]\n",
            "\n",
            " [[ 4  0  0  5  6  0  0  4]\n",
            "  [ 1  1  0  3  2  0  1  1]\n",
            "  [ 0  0  0  3  0  2  0  0]\n",
            "  [ 0 -3  0  1  0  1  0  0]\n",
            "  [ 0  0  0 -1  1  0  0  0]\n",
            "  [ 0 -5 -2  0 -1 -1  0  0]\n",
            "  [-1 -1  0 -2  0  0 -1 -1]\n",
            "  [-4  0 -3  0 -6  0  0 -4]]]\n"
          ]
        }
      ],
      "source": [
        "bitboard_dataset=np.array(bitboard_dataset)\n",
        "print(bitboard_dataset[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L54mHai3qOOI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696364461943,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# labels=d1['Evaluation']\n",
        "labels=d1['Scaled_Evaluation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "P2IV6TeU2O9W",
        "outputId": "e9b9e62d-4b33-40fc-ee04-c4f550fa956d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696364483043,
          "user_tz": -330,
          "elapsed": 19890,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'labels' is your list or array of labels\n",
        "indices = list(range(len(labels)))\n",
        "\n",
        "plt.plot(indices, labels, marker='o', linestyle='-', color='b')\n",
        "plt.title('Label Values Over Indices')\n",
        "plt.xlabel('Indices')\n",
        "plt.ylabel('Label Values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bnfn9WPEni1p",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696364522321,
          "user_tz": -330,
          "elapsed": 29416,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "np.save('/content/bitboard_dataset_10M.npy', bitboard_dataset)\n",
        "np.save('/content/labels_dataset_10M.npy', labels)\n",
        "\n",
        "# bitboard_dataset=np.load(\"/content/chess-numpy-dataset/bitboard_dataset_1M.npy\")\n",
        "# labels=np.load(\"/content/chess-numpy-dataset/labels_dataset.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-storage\n",
        "import os\n",
        "\n",
        "# Replace 'path/to/service-account-key.json' with the path to your service account key file\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/gleaming-modem-400906-3780658b0f47.json'\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "# Replace 'your-bucket-name' with the name of your Google Cloud Storage bucket\n",
        "bucket_name = 'chess_data_all'\n",
        "\n",
        "# Save the array to a binary file\n",
        "file_path = '/content/labels_dataset_10M.npy'\n",
        "\n",
        "# Create a Google Cloud Storage client\n",
        "client = storage.Client()\n",
        "\n",
        "# Specify the destination blob (file) in your bucket\n",
        "blob_name = 'labels_dataset_10M.npy'\n",
        "\n",
        "# Upload the file to the bucket\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "blob.upload_from_filename(file_path)\n",
        "\n",
        "print(f\"File uploaded to: gs://{bucket_name}/{blob_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma1A_N8GXb1G",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1696368284582,
          "user_tz": -330,
          "elapsed": 10723,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "da257c2a-1db6-4a72-db4d-fb3123e3d41c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.6.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mFile uploaded to: gs://chess_data_all/labels_dataset_10M.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y9qEfiSErKrv",
        "outputId": "dbc85ec6-c2ec-4c1b-c317-6478a9b221f1",
        "executionInfo": {
          "status": "error",
          "timestamp": 1696367463220,
          "user_tz": -330,
          "elapsed": 1656195,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 15, 8, 8, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv3d (Conv3D)             (None, 1, 1, 1, 8)           7688      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv3d_1 (Conv3D)           (None, 1, 4, 4, 4)           1504      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv3d_2 (Conv3D)           (None, 15, 1, 1, 8)          520       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 8)                    0         ['conv3d[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 64)                   0         ['conv3d_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 120)                  0         ['conv3d_2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 192)                  0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]',           \n",
            "                                                                     'flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 192)                  768       ['concatenate[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 192)                  0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   12352     ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 64)                   256       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 32)                   2080      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32)                   128       ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 16)                   528       ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 16)                   64        ['dense_2[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    17        ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25905 (101.19 KB)\n",
            "Trainable params: 25297 (98.82 KB)\n",
            "Non-trainable params: 608 (2.38 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "710/710 [==============================] - 27s 18ms/step - loss: 11598.2471 - mean_absolute_error: 39.7277 - val_loss: 10009.8848 - val_mean_absolute_error: 37.6516\n",
            "Epoch 2/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 8723.1670 - mean_absolute_error: 36.2156 - val_loss: 8242.5762 - val_mean_absolute_error: 36.8529\n",
            "Epoch 3/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7917.7505 - mean_absolute_error: 35.8287 - val_loss: 7965.5649 - val_mean_absolute_error: 36.1720\n",
            "Epoch 4/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7666.8560 - mean_absolute_error: 35.4067 - val_loss: 7820.0630 - val_mean_absolute_error: 35.7737\n",
            "Epoch 5/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7513.0762 - mean_absolute_error: 35.0576 - val_loss: 7720.5273 - val_mean_absolute_error: 35.0615\n",
            "Epoch 6/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7397.0171 - mean_absolute_error: 34.7844 - val_loss: 7629.4058 - val_mean_absolute_error: 34.8824\n",
            "Epoch 7/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7309.1772 - mean_absolute_error: 34.5632 - val_loss: 7553.0908 - val_mean_absolute_error: 34.7966\n",
            "Epoch 8/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7227.0752 - mean_absolute_error: 34.3824 - val_loss: 7551.3545 - val_mean_absolute_error: 35.2751\n",
            "Epoch 9/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7169.0825 - mean_absolute_error: 34.2430 - val_loss: 7517.7896 - val_mean_absolute_error: 34.5396\n",
            "Epoch 10/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7110.2534 - mean_absolute_error: 34.1092 - val_loss: 7488.9917 - val_mean_absolute_error: 34.2308\n",
            "Epoch 11/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7056.0854 - mean_absolute_error: 33.9672 - val_loss: 7438.5317 - val_mean_absolute_error: 34.4757\n",
            "Epoch 12/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 7015.4893 - mean_absolute_error: 33.8812 - val_loss: 7429.3730 - val_mean_absolute_error: 34.8018\n",
            "Epoch 13/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6979.5117 - mean_absolute_error: 33.7982 - val_loss: 7437.7666 - val_mean_absolute_error: 34.5548\n",
            "Epoch 14/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6939.0625 - mean_absolute_error: 33.7065 - val_loss: 7391.2466 - val_mean_absolute_error: 34.2318\n",
            "Epoch 15/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6904.5103 - mean_absolute_error: 33.6148 - val_loss: 7335.3481 - val_mean_absolute_error: 34.0953\n",
            "Epoch 16/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6878.6133 - mean_absolute_error: 33.5798 - val_loss: 7300.5591 - val_mean_absolute_error: 34.0986\n",
            "Epoch 17/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6847.8149 - mean_absolute_error: 33.5004 - val_loss: 7334.0405 - val_mean_absolute_error: 34.1852\n",
            "Epoch 18/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6820.9443 - mean_absolute_error: 33.4431 - val_loss: 7314.1753 - val_mean_absolute_error: 34.3854\n",
            "Epoch 19/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6799.7148 - mean_absolute_error: 33.3927 - val_loss: 7302.6221 - val_mean_absolute_error: 34.4626\n",
            "Epoch 20/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6769.6250 - mean_absolute_error: 33.3182 - val_loss: 7264.0308 - val_mean_absolute_error: 34.3261\n",
            "Epoch 21/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6754.1182 - mean_absolute_error: 33.2970 - val_loss: 7222.5273 - val_mean_absolute_error: 34.0668\n",
            "Epoch 22/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6732.8447 - mean_absolute_error: 33.2270 - val_loss: 7223.4937 - val_mean_absolute_error: 34.3724\n",
            "Epoch 23/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6717.1577 - mean_absolute_error: 33.1954 - val_loss: 7213.4219 - val_mean_absolute_error: 33.9551\n",
            "Epoch 24/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6694.5972 - mean_absolute_error: 33.1527 - val_loss: 7236.1001 - val_mean_absolute_error: 34.1175\n",
            "Epoch 25/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6684.2212 - mean_absolute_error: 33.1157 - val_loss: 7264.2925 - val_mean_absolute_error: 34.1023\n",
            "Epoch 26/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6668.8545 - mean_absolute_error: 33.0681 - val_loss: 7173.4844 - val_mean_absolute_error: 33.7323\n",
            "Epoch 27/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6652.2778 - mean_absolute_error: 33.0448 - val_loss: 7152.3916 - val_mean_absolute_error: 33.4587\n",
            "Epoch 28/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6641.8418 - mean_absolute_error: 33.0029 - val_loss: 7178.9473 - val_mean_absolute_error: 33.6648\n",
            "Epoch 29/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6624.1582 - mean_absolute_error: 32.9552 - val_loss: 7166.7598 - val_mean_absolute_error: 33.5878\n",
            "Epoch 30/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6610.3271 - mean_absolute_error: 32.9202 - val_loss: 7158.9155 - val_mean_absolute_error: 33.5043\n",
            "Epoch 31/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6598.5552 - mean_absolute_error: 32.8899 - val_loss: 7134.0210 - val_mean_absolute_error: 33.5656\n",
            "Epoch 32/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6589.7021 - mean_absolute_error: 32.8598 - val_loss: 7149.4111 - val_mean_absolute_error: 34.0559\n",
            "Epoch 33/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6577.9258 - mean_absolute_error: 32.8368 - val_loss: 7100.3271 - val_mean_absolute_error: 33.4431\n",
            "Epoch 34/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6565.1704 - mean_absolute_error: 32.7867 - val_loss: 7155.1533 - val_mean_absolute_error: 33.9908\n",
            "Epoch 35/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6551.2095 - mean_absolute_error: 32.7603 - val_loss: 7188.6353 - val_mean_absolute_error: 33.6035\n",
            "Epoch 36/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6542.7227 - mean_absolute_error: 32.7401 - val_loss: 7130.0210 - val_mean_absolute_error: 33.6221\n",
            "Epoch 37/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6535.2568 - mean_absolute_error: 32.7283 - val_loss: 7135.8540 - val_mean_absolute_error: 33.4115\n",
            "Epoch 38/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6525.3115 - mean_absolute_error: 32.6762 - val_loss: 7102.2856 - val_mean_absolute_error: 33.3553\n",
            "Epoch 39/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6511.6445 - mean_absolute_error: 32.6454 - val_loss: 7206.1118 - val_mean_absolute_error: 33.7309\n",
            "Epoch 40/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6502.0317 - mean_absolute_error: 32.6173 - val_loss: 7133.8325 - val_mean_absolute_error: 33.5224\n",
            "Epoch 41/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6499.0425 - mean_absolute_error: 32.6117 - val_loss: 7128.7642 - val_mean_absolute_error: 33.8432\n",
            "Epoch 42/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6487.4976 - mean_absolute_error: 32.5768 - val_loss: 7122.4790 - val_mean_absolute_error: 33.6408\n",
            "Epoch 43/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6473.7021 - mean_absolute_error: 32.5477 - val_loss: 7091.4355 - val_mean_absolute_error: 33.2541\n",
            "Epoch 44/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6473.1768 - mean_absolute_error: 32.5355 - val_loss: 7080.8652 - val_mean_absolute_error: 33.3298\n",
            "Epoch 45/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6461.7129 - mean_absolute_error: 32.5191 - val_loss: 7096.0522 - val_mean_absolute_error: 33.5008\n",
            "Epoch 46/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6452.6494 - mean_absolute_error: 32.5032 - val_loss: 7099.4717 - val_mean_absolute_error: 33.5263\n",
            "Epoch 47/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6446.6606 - mean_absolute_error: 32.4802 - val_loss: 7110.6333 - val_mean_absolute_error: 34.0278\n",
            "Epoch 48/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6448.2310 - mean_absolute_error: 32.4742 - val_loss: 7075.8755 - val_mean_absolute_error: 33.6372\n",
            "Epoch 49/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6439.6030 - mean_absolute_error: 32.4630 - val_loss: 7065.5728 - val_mean_absolute_error: 33.0631\n",
            "Epoch 50/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6422.5942 - mean_absolute_error: 32.4273 - val_loss: 7133.1074 - val_mean_absolute_error: 33.8785\n",
            "Epoch 51/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6417.4673 - mean_absolute_error: 32.4152 - val_loss: 7135.1304 - val_mean_absolute_error: 33.7406\n",
            "Epoch 52/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6413.7812 - mean_absolute_error: 32.4111 - val_loss: 7132.0254 - val_mean_absolute_error: 33.5363\n",
            "Epoch 53/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6408.2808 - mean_absolute_error: 32.3992 - val_loss: 7206.8857 - val_mean_absolute_error: 33.5327\n",
            "Epoch 54/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6406.1748 - mean_absolute_error: 32.3765 - val_loss: 7119.5063 - val_mean_absolute_error: 33.6447\n",
            "Epoch 55/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6397.7393 - mean_absolute_error: 32.3626 - val_loss: 7052.4243 - val_mean_absolute_error: 33.0046\n",
            "Epoch 56/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6392.7046 - mean_absolute_error: 32.3515 - val_loss: 7084.8662 - val_mean_absolute_error: 33.0279\n",
            "Epoch 57/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6382.9424 - mean_absolute_error: 32.3321 - val_loss: 7064.5376 - val_mean_absolute_error: 33.1153\n",
            "Epoch 58/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6392.4829 - mean_absolute_error: 32.3570 - val_loss: 7085.9614 - val_mean_absolute_error: 33.6456\n",
            "Epoch 59/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6375.9526 - mean_absolute_error: 32.3163 - val_loss: 7106.2656 - val_mean_absolute_error: 33.6574\n",
            "Epoch 60/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6370.4580 - mean_absolute_error: 32.3026 - val_loss: 7069.9121 - val_mean_absolute_error: 33.0089\n",
            "Epoch 61/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6370.7520 - mean_absolute_error: 32.2908 - val_loss: 7110.6748 - val_mean_absolute_error: 33.4709\n",
            "Epoch 62/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6365.5317 - mean_absolute_error: 32.2858 - val_loss: 7074.0723 - val_mean_absolute_error: 33.3263\n",
            "Epoch 63/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6356.3569 - mean_absolute_error: 32.2605 - val_loss: 7055.3672 - val_mean_absolute_error: 33.2198\n",
            "Epoch 64/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6356.6860 - mean_absolute_error: 32.2705 - val_loss: 7097.5327 - val_mean_absolute_error: 33.3909\n",
            "Epoch 65/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6353.6040 - mean_absolute_error: 32.2519 - val_loss: 7068.9609 - val_mean_absolute_error: 33.5294\n",
            "Epoch 66/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6344.9878 - mean_absolute_error: 32.2499 - val_loss: 7095.5078 - val_mean_absolute_error: 33.2397\n",
            "Epoch 67/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6341.7832 - mean_absolute_error: 32.2412 - val_loss: 7112.8203 - val_mean_absolute_error: 33.1763\n",
            "Epoch 68/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6333.6011 - mean_absolute_error: 32.2297 - val_loss: 7091.6172 - val_mean_absolute_error: 33.4676\n",
            "Epoch 69/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6335.9761 - mean_absolute_error: 32.2231 - val_loss: 7100.1489 - val_mean_absolute_error: 33.4582\n",
            "Epoch 70/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6328.9180 - mean_absolute_error: 32.2035 - val_loss: 7043.0029 - val_mean_absolute_error: 33.1457\n",
            "Epoch 71/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6328.6074 - mean_absolute_error: 32.2118 - val_loss: 7083.9409 - val_mean_absolute_error: 33.2415\n",
            "Epoch 72/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6326.3086 - mean_absolute_error: 32.1895 - val_loss: 7035.6870 - val_mean_absolute_error: 33.1099\n",
            "Epoch 73/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6312.0181 - mean_absolute_error: 32.1704 - val_loss: 7092.1772 - val_mean_absolute_error: 33.9998\n",
            "Epoch 74/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6318.5854 - mean_absolute_error: 32.1778 - val_loss: 7069.1831 - val_mean_absolute_error: 33.5340\n",
            "Epoch 75/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6306.1001 - mean_absolute_error: 32.1534 - val_loss: 7065.2729 - val_mean_absolute_error: 33.2958\n",
            "Epoch 76/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6307.4058 - mean_absolute_error: 32.1592 - val_loss: 7093.8979 - val_mean_absolute_error: 32.9722\n",
            "Epoch 77/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6308.1230 - mean_absolute_error: 32.1508 - val_loss: 7065.2695 - val_mean_absolute_error: 33.3138\n",
            "Epoch 78/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6297.5576 - mean_absolute_error: 32.1332 - val_loss: 7124.8823 - val_mean_absolute_error: 33.7939\n",
            "Epoch 79/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6291.6157 - mean_absolute_error: 32.1242 - val_loss: 7085.8145 - val_mean_absolute_error: 33.2756\n",
            "Epoch 80/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6292.3135 - mean_absolute_error: 32.1114 - val_loss: 7090.9062 - val_mean_absolute_error: 33.6570\n",
            "Epoch 81/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6292.3633 - mean_absolute_error: 32.1184 - val_loss: 7057.0557 - val_mean_absolute_error: 33.4665\n",
            "Epoch 82/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6287.6099 - mean_absolute_error: 32.1091 - val_loss: 7099.8965 - val_mean_absolute_error: 33.6233\n",
            "Epoch 83/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6284.1621 - mean_absolute_error: 32.1054 - val_loss: 7081.8794 - val_mean_absolute_error: 32.9196\n",
            "Epoch 84/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6284.7437 - mean_absolute_error: 32.1047 - val_loss: 7078.7280 - val_mean_absolute_error: 33.2607\n",
            "Epoch 85/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6274.0352 - mean_absolute_error: 32.0711 - val_loss: 7085.9453 - val_mean_absolute_error: 34.1367\n",
            "Epoch 86/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6269.4023 - mean_absolute_error: 32.0728 - val_loss: 7145.8062 - val_mean_absolute_error: 33.7252\n",
            "Epoch 87/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6269.4922 - mean_absolute_error: 32.0727 - val_loss: 7106.2515 - val_mean_absolute_error: 33.2150\n",
            "Epoch 88/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6269.6665 - mean_absolute_error: 32.0770 - val_loss: 7047.4507 - val_mean_absolute_error: 32.9875\n",
            "Epoch 89/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6258.6167 - mean_absolute_error: 32.0472 - val_loss: 7127.1118 - val_mean_absolute_error: 33.7178\n",
            "Epoch 90/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6261.7891 - mean_absolute_error: 32.0553 - val_loss: 7071.1479 - val_mean_absolute_error: 32.9661\n",
            "Epoch 91/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6255.7969 - mean_absolute_error: 32.0404 - val_loss: 7090.7876 - val_mean_absolute_error: 33.4523\n",
            "Epoch 92/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6255.9375 - mean_absolute_error: 32.0378 - val_loss: 7090.8716 - val_mean_absolute_error: 33.6794\n",
            "Epoch 93/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6249.2314 - mean_absolute_error: 32.0268 - val_loss: 7097.0269 - val_mean_absolute_error: 33.6248\n",
            "Epoch 94/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6252.9287 - mean_absolute_error: 32.0303 - val_loss: 7145.2119 - val_mean_absolute_error: 34.1181\n",
            "Epoch 95/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6248.2588 - mean_absolute_error: 32.0257 - val_loss: 7126.0854 - val_mean_absolute_error: 33.8341\n",
            "Epoch 96/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6245.0654 - mean_absolute_error: 32.0085 - val_loss: 7141.7202 - val_mean_absolute_error: 33.7748\n",
            "Epoch 97/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6243.0215 - mean_absolute_error: 32.0167 - val_loss: 7069.5469 - val_mean_absolute_error: 33.5906\n",
            "Epoch 98/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6242.3599 - mean_absolute_error: 32.0029 - val_loss: 7065.6870 - val_mean_absolute_error: 33.2137\n",
            "Epoch 99/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6233.8203 - mean_absolute_error: 31.9931 - val_loss: 7096.2188 - val_mean_absolute_error: 33.1804\n",
            "Epoch 100/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6235.8643 - mean_absolute_error: 31.9964 - val_loss: 7130.6387 - val_mean_absolute_error: 33.9511\n",
            "Epoch 101/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6227.5264 - mean_absolute_error: 31.9763 - val_loss: 7131.4844 - val_mean_absolute_error: 33.8614\n",
            "Epoch 102/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6236.3550 - mean_absolute_error: 31.9932 - val_loss: 7137.2295 - val_mean_absolute_error: 34.5793\n",
            "Epoch 103/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6229.9956 - mean_absolute_error: 31.9888 - val_loss: 7090.7773 - val_mean_absolute_error: 33.1110\n",
            "Epoch 104/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6219.7480 - mean_absolute_error: 31.9619 - val_loss: 7139.6670 - val_mean_absolute_error: 33.9914\n",
            "Epoch 105/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6224.2109 - mean_absolute_error: 31.9724 - val_loss: 7078.2827 - val_mean_absolute_error: 32.9456\n",
            "Epoch 106/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6219.0781 - mean_absolute_error: 31.9534 - val_loss: 7093.4917 - val_mean_absolute_error: 33.1052\n",
            "Epoch 107/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6216.1592 - mean_absolute_error: 31.9557 - val_loss: 7104.1152 - val_mean_absolute_error: 33.1989\n",
            "Epoch 108/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6215.8291 - mean_absolute_error: 31.9553 - val_loss: 7060.8569 - val_mean_absolute_error: 33.1132\n",
            "Epoch 109/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6217.4038 - mean_absolute_error: 31.9506 - val_loss: 7058.1841 - val_mean_absolute_error: 32.9905\n",
            "Epoch 110/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6214.4678 - mean_absolute_error: 31.9538 - val_loss: 7066.6719 - val_mean_absolute_error: 33.0093\n",
            "Epoch 111/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6209.9009 - mean_absolute_error: 31.9391 - val_loss: 7071.4741 - val_mean_absolute_error: 33.1201\n",
            "Epoch 112/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6204.2866 - mean_absolute_error: 31.9270 - val_loss: 7104.3120 - val_mean_absolute_error: 33.2767\n",
            "Epoch 113/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6205.8633 - mean_absolute_error: 31.9199 - val_loss: 7128.5718 - val_mean_absolute_error: 33.7951\n",
            "Epoch 114/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6201.5996 - mean_absolute_error: 31.9269 - val_loss: 7043.0068 - val_mean_absolute_error: 33.0891\n",
            "Epoch 115/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6203.8062 - mean_absolute_error: 31.9273 - val_loss: 7143.7954 - val_mean_absolute_error: 34.0167\n",
            "Epoch 116/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6197.8730 - mean_absolute_error: 31.9189 - val_loss: 7136.3960 - val_mean_absolute_error: 34.3952\n",
            "Epoch 117/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6199.3184 - mean_absolute_error: 31.9254 - val_loss: 7091.1221 - val_mean_absolute_error: 32.9182\n",
            "Epoch 118/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6197.0088 - mean_absolute_error: 31.9156 - val_loss: 7154.7705 - val_mean_absolute_error: 33.3842\n",
            "Epoch 119/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6197.5049 - mean_absolute_error: 31.9145 - val_loss: 7219.9194 - val_mean_absolute_error: 35.9403\n",
            "Epoch 120/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6187.9312 - mean_absolute_error: 31.9112 - val_loss: 7163.8574 - val_mean_absolute_error: 33.0890\n",
            "Epoch 121/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6185.4351 - mean_absolute_error: 31.8937 - val_loss: 7069.2319 - val_mean_absolute_error: 32.9200\n",
            "Epoch 122/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6188.1123 - mean_absolute_error: 31.9001 - val_loss: 7100.8066 - val_mean_absolute_error: 33.3007\n",
            "Epoch 123/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6179.6035 - mean_absolute_error: 31.8823 - val_loss: 7133.2510 - val_mean_absolute_error: 34.1864\n",
            "Epoch 124/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6184.8530 - mean_absolute_error: 31.9014 - val_loss: 7145.0908 - val_mean_absolute_error: 34.2031\n",
            "Epoch 125/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6182.4238 - mean_absolute_error: 31.8905 - val_loss: 7070.1699 - val_mean_absolute_error: 32.9342\n",
            "Epoch 126/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6180.0000 - mean_absolute_error: 31.8729 - val_loss: 7130.5244 - val_mean_absolute_error: 33.8655\n",
            "Epoch 127/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6180.5122 - mean_absolute_error: 31.8866 - val_loss: 7086.5376 - val_mean_absolute_error: 32.8527\n",
            "Epoch 128/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6174.4829 - mean_absolute_error: 31.8739 - val_loss: 7076.1235 - val_mean_absolute_error: 32.9624\n",
            "Epoch 129/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6176.6943 - mean_absolute_error: 31.8693 - val_loss: 7107.1138 - val_mean_absolute_error: 33.1918\n",
            "Epoch 130/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6179.1592 - mean_absolute_error: 31.8914 - val_loss: 7072.5747 - val_mean_absolute_error: 33.2057\n",
            "Epoch 131/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6173.0088 - mean_absolute_error: 31.8710 - val_loss: 7133.2861 - val_mean_absolute_error: 34.0721\n",
            "Epoch 132/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6172.2695 - mean_absolute_error: 31.8594 - val_loss: 7114.4653 - val_mean_absolute_error: 33.4417\n",
            "Epoch 133/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6169.6182 - mean_absolute_error: 31.8624 - val_loss: 7127.3525 - val_mean_absolute_error: 34.2956\n",
            "Epoch 134/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6165.1362 - mean_absolute_error: 31.8502 - val_loss: 7117.1553 - val_mean_absolute_error: 33.6713\n",
            "Epoch 135/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6166.2412 - mean_absolute_error: 31.8468 - val_loss: 7112.2524 - val_mean_absolute_error: 33.0852\n",
            "Epoch 136/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6161.8013 - mean_absolute_error: 31.8451 - val_loss: 7120.0977 - val_mean_absolute_error: 33.1935\n",
            "Epoch 137/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6166.1577 - mean_absolute_error: 31.8559 - val_loss: 7084.0151 - val_mean_absolute_error: 33.0187\n",
            "Epoch 138/300\n",
            "710/710 [==============================] - 12s 16ms/step - loss: 6162.1982 - mean_absolute_error: 31.8490 - val_loss: 7089.2334 - val_mean_absolute_error: 32.9276\n",
            "Epoch 139/300\n",
            "710/710 [==============================] - 11s 16ms/step - loss: 6159.9224 - mean_absolute_error: 31.8317 - val_loss: 7093.9102 - val_mean_absolute_error: 33.1268\n",
            "Epoch 140/300\n",
            "141/710 [====>.........................] - ETA: 8s - loss: 6112.0220 - mean_absolute_error: 31.7178"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e87f187ce5c1>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "bitboard_dataset = np.array(bitboard_dataset)\n",
        "bitboard_dataset, labels = shuffle(bitboard_dataset, labels, random_state=20)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(bitboard_dataset, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 15, 8, 8, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 15, 8, 8, 1)\n",
        "\n",
        "# Input layer\n",
        "input_layer = layers.Input(shape=(15, 8, 8, 1))\n",
        "\n",
        "# Parallel convolutional layers\n",
        "conv1 = layers.Conv3D(8, (15, 8, 8), activation='relu')(input_layer)\n",
        "conv2 = layers.Conv3D(4, (15, 5, 5), activation='relu')(input_layer)\n",
        "conv3 = layers.Conv3D(8, (1, 8, 8), activation='relu')(input_layer)\n",
        "\n",
        "# Flatten the outputs of convolutional layers\n",
        "flatten1 = layers.Flatten()(conv1)\n",
        "flatten2 = layers.Flatten()(conv2)\n",
        "flatten3 = layers.Flatten()(conv3)\n",
        "\n",
        "# Concatenate the outputs of parallel convolutions\n",
        "merged = layers.concatenate([flatten1,flatten2, flatten3], axis=-1)\n",
        "\n",
        "# Additional layers\n",
        "batch_norm1 = layers.BatchNormalization()(merged)\n",
        "flatten = layers.Flatten()(batch_norm1)\n",
        "\n",
        "dense1 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(flatten)\n",
        "batch_norm2 = layers.BatchNormalization()(dense1)\n",
        "\n",
        "dense2 = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(batch_norm2)\n",
        "batch_norm3 = layers.BatchNormalization()(dense2)\n",
        "\n",
        "dense3 = layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01))(batch_norm3)\n",
        "batch_norm4 = layers.BatchNormalization()(dense3)\n",
        "\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(1)(batch_norm4)\n",
        "\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=10000, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Mean Absolute Error:\", mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lx_ulGlEr0KK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1696367563331,
          "user_tz": -330,
          "elapsed": 2337,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ecdcaae6-4cdf-4be7-8892-484c84dce14c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-851a245417c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/model1.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/model1.keras'"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/model1.keras')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}